\chapter{数字人视频生成系统设计}

Emo Hallo 系统采用分层 C/S 架构，将用户交互、接口处理、任务调度与模型推理解耦为五个层次。前端基于 Streamlit 构建交互界面，后端以 FastAPI + Uvicorn 提供 RESTful 接口，推理层集成 Hallo2 模型完成音频驱动的视频生成。系统在启动阶段预加载模型权重（耗时约 12 分钟），运行时通过异步队列约束并发数量（默认单任务串行），避免 GPU 显存溢出；前后端通过 HTTP 协商状态，前端以 2 秒周期轮询任务进度，后端异步执行推理并回写结果。

本章从需求约束出发，分析架构选型理由、明确模块职责边界，并给出关键设计决策的 trade-off 考量。第~\ref{sec:requirements} 节给出应用背景与需求分析；第~\ref{sec:arch-design} 节阐述分层架构与模块划分；第~\ref{sec:tech-stack} 节对比技术栈选型；第~\ref{sec:design-summary} 节总结设计要点。

\section{应用背景与需求分析}
\label{sec:requirements}

\subsection{应用背景}

近年来，音频驱动的 Talking Head 生成已从“单帧口型变形”走向“长时序、高分辨率、可控表情”的工程化阶段。相关研究显示，扩散式视频生成在细节保真与时序一致性上具有优势，如 VASA-1 强调实时生成能力，FaceTalk 以音频条件的运动扩散提升可控性，ConsistTalk 通过噪声搜索强化跨帧一致性，而综合性综述工作对数据集与评测指标给出了系统梳理。上述方向共同指向三类核心瓶颈：身份一致性、音视频同步与长时序稳定性。在应用侧，这些瓶颈往往转化为推理成本、资源治理与交互体验之间的权衡问题。

\subsubsection{传统视频制作的局限性}

传统视频生产链路通常面临如下约束：
\begin{itemize}
    \item \textbf{链路冗长}：从脚本、拍摄到后期调色与剪辑，迭代周期长且难以并行。
    \item \textbf{资源耦合}：人员档期、场地与设备强依赖，变更导致重拍与成本外溢。
    \item \textbf{资产复用弱}：素材与风格难以模块化复用，版本迭代不具备“增量生成”能力。
    \item \textbf{质量稳定性差}：受现场环境与制作流程影响，输出一致性较难保证。
    \item \textbf{跨地域协同高成本}：跨时区制作与审片成本高，生产节奏受限。
\end{itemize}

\subsubsection{虚拟主播/数字人技术的优势}

相较传统流程，数字人系统具备更强的工程化优势：
\begin{itemize}
    \item \textbf{边际成本低}：一次性采集即可复用身份与素材，生成成本可控。
    \item \textbf{生成节拍快}：模型推理可批量化执行，适合高频内容生产。
    \item \textbf{可编排性强}：身份、音频与参数可拆分配置，便于快速调参与迁移。
    \item \textbf{稳定输出}：同一输入在相同配置下具备可复现性，有利于质量控制。
    \item \textbf{本地化友好}：多语种音频驱动即可适配不同市场语境。
\end{itemize}

\subsubsection{核心应用场景}

虚拟主播技术在以下领域具有显著的应用价值：

\begin{itemize}
    \item \textbf{直播电商}：实时生成带货直播，克服场景限制和时间约束
    \item \textbf{在线教育}：生成教学视频，支持多个讲师的课程快速录制
    \item \textbf{客户服务}：生成虚拟客服，提供 24/7 的多语言支持
    \item \textbf{企业宣传}：快速生成企业宣传视频、产品演示视频
    \item \textbf{内容创作}：为内容创作者提供虚拟形象，降低创作门槛
    \item \textbf{国际化运营}：快速适配不同国家和地区的内容需求
\end{itemize}

\subsubsection{相关研究工作}

扩散模型为高保真视频生成提供了稳定的优化范式，在口型细节与表情演化方面优于早期 GAN 方案。围绕音频驱动的人脸动画，研究路线主要集中在三条主线：其一是音频条件注入与语义对齐，其二是面部区域的局部约束与掩码控制，其三是跨帧时序一致性的建模与抖动抑制。以 Hallo2 为代表的方案在扩散式视频生成框架中引入“参考图像条件 + 音频驱动运动”的联合建模，通过参考图像分支编码身份与风格，并将音频特征映射为运动驱动信号，配合人脸定位与掩码约束提升面部稳定性。VASA-1 与 FaceTalk 等工作分别强调实时性与音频驱动的运动扩散，而 ConsistTalk 通过噪声搜索策略强化时序一致性；这些成果为系统侧的工程化落地提供了设计锚点。

基于上述路线，本文以 Hallo2 作为核心推理模型，构建面向应用的系统实现：通过分层架构与异步任务队列实现交互与推理解耦；通过并发限流与模型常驻机制降低显存冲突；并在前端提供可观测的进度与结果分发能力，使数字人视频生成以可复现、可扩展的方式服务于实际场景。

\subsection{需求分析}

\subsubsection{功能需求}

系统在应用侧需覆盖多媒体输入、异步任务、结果分发与运行状态可观测等需求，核心功能如下：

\begin{enumerate}
    \item \textbf{多媒体输入与校验}
    \begin{itemize}
        \item 支持多张人物图像与多段音频上传，前端可选择当前输入组合
        \item 前端与后端双重校验文件扩展名（JPG/PNG 与 WAV/MP3/OGG/M4A）
        \item 前端将输入暂存于系统临时目录，后端写入任务工区（具体路径见实现章节）
        \item 上传后保留文件名与类型，以便后端进行格式校验与解码
    \end{itemize}

    \item \textbf{任务创建与进度反馈}
    \begin{itemize}
        \item 前端提交 \texttt{/api/v1/inference/hallo2} 创建异步任务，返回 \texttt{task\_id}
        \item 任务进度通过轮询 \texttt{/api/v1/tasks/\{task\_id\}} 获取，刷新间隔默认 2 s
        \item 任务状态返回 \texttt{status}、\texttt{progress}、\texttt{status\_message} 与 ETA
        \item 任务 ID 通过 URL query 参数持久化，避免刷新导致状态丢失
    \end{itemize}

    \item \textbf{结果展示与分发}
    \begin{itemize}
        \item 支持生成结果预览与下载，视频通过 \texttt{/api/v1/tasks/\{task\_id\}/video} 获取
        \item 前端提供 Recent Creations 列表，默认展示最近 10 个完成任务
        \item 结果下载可缓存至本地临时目录，减少重复拉取
        \item 后端支持任务队列中的取消操作（\texttt{DELETE /api/v1/tasks/\{task\_id\}}）
    \end{itemize}

    \item \textbf{运行状态与模型信息}
    \begin{itemize}
        \item \texttt{/health} 提供轻量级就绪探测，\texttt{/api/v1/health} 输出 GPU 与模型状态
        \item \texttt{/api/v1/models} 与 \texttt{/api/v1/models/\{name\}} 提供模型注册信息
        \item 推理参数可通过 \texttt{/api/v1/inference/hallo2/config} 更新（如步数、缓存开关）
        \item 前后端日志分离输出，便于独立追踪与故障定位
    \end{itemize}

    \item \textbf{国际化与多语言}
    \begin{itemize}
        \item 前端支持多语言切换（含中英文及多语种选项）
        \item 语言配置写入运行配置，跨刷新保持一致
    \end{itemize}

    \item \textbf{API接口服务}
    \begin{itemize}
        \item 采用 RESTful API 支持第三方调用，覆盖任务提交、状态查询与结果下载
        \item 接口以 JSON 结果与 HTTP 状态码表达执行结果与异常信息
        \item API 与前端通过统一的 \texttt{BACKEND\_URL} 环境变量解耦部署
    \end{itemize}
\end{enumerate}

\subsubsection{性能需求}

系统的性能需求主要包括以下方面：

\begin{enumerate}
    \item \textbf{生成效率与启动开销}
    \begin{itemize}
        \item 后端在生命周期启动阶段预加载 Hallo2 模型，首次启动耗时约 5--15 分钟（取决于权重与显存）
        \item 任务提交为异步模式，前端获取 \texttt{task\_id} 后即可返回界面
        \item 推理耗时由音频长度、分辨率与采样步数决定，系统不在交互链路阻塞
    \end{itemize}

    \item \textbf{并发处理能力}
    \begin{itemize}
        \item API 层支持并发接入，推理侧通过 TaskManager 限制并发数量
        \item 默认 \texttt{max\_concurrent\_tasks=1}，避免单 GPU 显存争用
        \item 多余任务进入队列，后台线程在空闲后自动取出执行
    \end{itemize}

    \item \textbf{资源占用与缓存}
    \begin{itemize}
        \item 输入文件写入任务工区，输出视频落盘为 MP4
        \item 前端临时文件使用系统临时目录，避免阻塞主进程
        \item GPU 推理默认采用 \texttt{float16}（可用时），以降低显存压力
    \end{itemize}

    \item \textbf{交互响应与刷新}
    \begin{itemize}
        \item 任务进度刷新间隔默认 2 s，状态与最近结果带缓存以降低闪烁
        \item 健康检查超时默认 3 s，前端状态缓存窗口为 5 s
        \item 结果下载超时设置为 30 s，适配大文件传输场景
    \end{itemize}

    \item \textbf{可扩展性}
    \begin{itemize}
        \item 支持通过 \texttt{CUDA\_VISIBLE\_DEVICES} 选择 GPU
        \item 预留多模型注册与卸载能力，可扩展为多进程/多机推理
        \item 模型注册信息与配置均可独立更新
    \end{itemize}
\end{enumerate}

为增强论文的可复现性与评测的可比性，性能评估应明确给出测试环境配置与评价指标。测试环境建议至少包含 GPU 型号与显存容量、CUDA 版本、PyTorch 版本等关键信息；评价指标可从效率、资源与质量三个维度展开，包括平均生成耗时、吞吐量（任务/分钟）、显存峰值占用，以及视频质量相关指标（如 FID）与口型同步相关指标（如基于 SyncNet 的同步得分）。在此基础上，可选取同类系统或模型作为基线进行对比，形成定量化的综合评估结果，如表~\ref{tab:benchmark_placeholder}所示。

\begin{table}[htbp]
    \centering
    \caption{数字人视频生成性能与质量评测指标示例（结果可在实验章节给出）}
    \label{tab:benchmark_placeholder}
    \begin{tabular}{lcccc}
        \hline
        模型/系统 & 平均生成耗时（s） & 显存峰值（GB） & 质量指标（FID$\downarrow$） & 同步指标（LipSync$\uparrow$） \\
        \hline
        Hallo2（本文系统） & -- & -- & -- & -- \\
        基线方法 A & -- & -- & -- & -- \\
        基线方法 B & -- & -- & -- & -- \\
        \hline
    \end{tabular}
\end{table}

\subsubsection{可靠性需求}

系统的可靠性需求确保在各种异常情况下能稳定运行：

\begin{enumerate}
    \item \textbf{错误处理与输入防护}
    \begin{itemize}
        \item 后端对图像与音频格式进行强校验，非法请求直接返回 4xx
        \item 任务执行异常统一记录至后端日志，避免进程崩溃
        \item 前端对缺失输入与非法选择进行拦截，减少无效任务进入队列
    \end{itemize}

    \item \textbf{显存与并发治理}
    \begin{itemize}
        \item 任务并发通过 TaskManager 限制，默认单任务串行以降低显存争用
        \item 模型卸载时调用 \texttt{torch.cuda.empty\_cache()} 释放缓存
        \item GPU 可用时采用 \texttt{float16} 推理，降低显存峰值
    \end{itemize}

    \item \textbf{日志记录与可追踪性}
    \begin{itemize}
        \item 前后端日志分离存储，支持独立查询与审计
        \item 任务状态包含 \texttt{created\_at}、\texttt{started\_at} 与 \texttt{updated\_at} 时间戳
        \item 任务日志接口 \texttt{/api/v1/tasks/\{task\_id\}/logs} 提供运行输出查询
    \end{itemize}

    \item \textbf{资源清理与生命周期}
    \begin{itemize}
        \item FastAPI 生命周期结束时关闭 TaskManager 并卸载模型
        \item 启动脚本捕获信号并清理相关进程与端口占用
        \item 输入与输出以任务目录隔离，减少资源串扰
    \end{itemize}

    \item \textbf{健康检查与就绪探测}
    \begin{itemize}
        \item \texttt{/health} 用于快速就绪探测，\texttt{/api/v1/health} 输出 GPU 与模型信息
        \item 启动脚本后台轮询健康检查接口，提示模型加载进度
        \item 前端状态栏展示后端可用性与队列情况
    \end{itemize}

    \item \textbf{容错能力}
    \begin{itemize}
        \item 支持取消队列中未执行任务，避免无效资源占用
        \item 任务状态可恢复查询，但内存态不跨进程持久化
        \item 各任务文件独立存储，降低交叉污染风险
    \end{itemize}
\end{enumerate}

除机制设计外，可靠性需求还应通过验证策略加以支撑。本文在系统验证阶段可采用“压力测试 + 异常注入”的组合方法：在压力测试中逐步提升请求并发与任务队列长度，观察系统的吞吐、延迟抖动以及资源占用变化；在异常注入中模拟输入文件损坏、模型加载失败、显存不足（OOM）、磁盘写入异常及服务重启等场景，检查系统能否保持服务存活、任务状态可追踪以及资源可回收。上述验证有助于将可靠性要求落到可观测、可复现的实验过程之中。

本节围绕应用背景与需求分析明确了系统的使用场景、关键挑战以及在功能、性能与可靠性方面的目标约束，为后续的系统总体架构设计与模块实现提供了需求依据与评价标准。

\section{系统架构设计}
\label{sec:arch-design}

\subsection{分层架构}

系统采用\textbf{分层 C/S（Client--Server）架构},将前端交互、接口处理、业务调度与模型推理解耦为五个层次。选择分层架构的核心考量包括:

\begin{itemize}
    \item \textbf{隔离GPU阻塞}:推理耗时长(单任务9--23分钟),若在交互线程同步执行将导致界面冻结;异步架构下前端提交任务即返回,后端队列调度推理,用户可同时查看历史结果或提交新任务。
    \item \textbf{约束显存争用}:Hallo2模型占用8--12GB基础显存,推理时额外需4--6GB;单 GPU 环境下若多任务并发将触发 OOM。任务队列配合并发限制(\texttt{max\_concurrent\_tasks=1})可串行化推理,避免显存冲突。
    \item \textbf{支持独立部署}:前后端通过 HTTP 解耦,可分别部署于不同节点;前端可在无 GPU 环境启动,后端可独立扩展为多进程/多机推理集群。
    \item \textbf{降低技术债务}:层间接口清晰,替换前端框架或推理模型时无需重构整个系统;例如可将 Streamlit 替换为 React,或将 Hallo2 替换为其他 Talking Head 模型。
\end{itemize}

根据功能边界与数据流向,系统可抽象为五层,如图~\ref{fig:system_architecture_layers}所示:

\begin{description}
    \item[展示层（Presentation Layer）] 面向用户的交互界面，负责文件上传、参数配置与结果展示。
    \item[API 层（API Layer）] 提供 RESTful 接口，完成请求路由、参数校验与响应封装。
    \item[服务层（Service Layer）] 承载核心业务逻辑，如任务管理、状态管理与模型管理。
    \item[推理层（Inference Layer）] 组织推理管线与数据处理流程，负责推理流程编排与执行。
    \item[模型层（Model Layer）] 集成深度学习框架与预训练模型，利用 GPU/CUDA 完成加速计算。
\end{description}

\begin{figure}[h]
    \centering
    \begin{tikzpicture}[
        scale=0.9,
        node distance=1.5cm,
        auto,
        font=\small,
        box/.style={rectangle, draw, thick, minimum width=7cm, minimum height=0.8cm,
                    align=center, fill=blue!10},
        title/.style={align=center, font=\large\bfseries},
        arrow/.style={->, thick, line width=1.5pt}
    ]

    % 标题
    \node[title] at (3.5, 9) {系统五层分层架构设计};

    % 展示层
    \node[box, fill=cyan!20] (presentation) at (3.5, 7.5) {\shortstack{\textbf{展示层（Presentation Layer）}\\Streamlit Web UI (Port 8501)}};

    % HTTP 通信
    \node[align=center] at (3.5, 6.8) {$\Downarrow$ HTTP REST 通信 $\Downarrow$};

    % API 层
    \node[box, fill=green!20] (api) at (3.5, 6) {\shortstack{\textbf{API 层（API Layer）}\\FastAPI + Uvicorn (Port 8001)}};

    % 函数调用
    \node[align=center] at (3.5, 5.3) {$\Downarrow$ 函数调用 $\Downarrow$};

    % 服务层
    \node[box, fill=yellow!20, minimum width=8cm] (service) at (3.5, 4.5) {\shortstack{\textbf{服务层（Service Layer）}\\TaskManager | StateManager | ModelRegistry}};

    % 函数调用
    \node[align=center] at (3.5, 3.8) {$\Downarrow$ 函数调用 $\Downarrow$};

    % 推理层
    \node[box, fill=orange!20, minimum width=8cm] (inference) at (3.5, 3) {\shortstack{\textbf{推理层（Inference Layer）}\\Hallo2 Pipeline | 数据处理器}};

    % 函数调用
    \node[align=center] at (3.5, 2.3) {$\Downarrow$ 函数调用 $\Downarrow$};

    % 模型层
    \node[box, fill=red!20, minimum width=8cm] (model) at (3.5, 1.5) {\shortstack{\textbf{模型层（Model Layer）}\\PyTorch + CUDA + 预训练模型}};

    % 右侧说明
    \node[align=center, anchor=west] at (11.5, 7.5) {\small \textbf{用户交互}};
    \node[align=center, anchor=west, font=\tiny] at (11.5, 7.1) {文件上传、参数配置};

    \node[align=center, anchor=west] at (11.5, 6) {\small \textbf{请求处理}};
    \node[align=center, anchor=west, font=\tiny] at (11.5, 5.6) {参数验证、路由};

    \node[align=center, anchor=west] at (11.5, 4.5) {\small \textbf{业务逻辑}};
    \node[align=center, anchor=west, font=\tiny] at (11.5, 4.1) {任务管理、状态管理};

    \node[align=center, anchor=west] at (11.5, 3) {\small \textbf{核心推理}};
    \node[align=center, anchor=west, font=\tiny] at (11.5, 2.6) {模型执行、数据处理};

    \node[align=center, anchor=west] at (11.5, 1.5) {\small \textbf{硬件基础}};
    \node[align=center, anchor=west, font=\tiny] at (11.5, 1.1) {深度学习框架};

    \end{tikzpicture}
    \caption{数字人视频生成系统五层分层架构}
    \label{fig:system_architecture_layers}
\end{figure}

该分层架构的设计收益主要体现在：
\begin{itemize}
    \item \textbf{关注点分离}：职责边界明确，降低模块间耦合，提高可维护性与可演化性。
    \item \textbf{异步解耦}：交互请求与 GPU 推理过程分离，提升接口响应速度并改善用户体验。
    \item \textbf{可控调度}：通过队列与并发限制实现资源可控的任务调度策略，降低资源争用风险。
    \item \textbf{部署与扩展}：各层可按需独立扩展，支持向多进程/多机的形态演进。
    \item \textbf{可测试性}：层间接口清晰，有利于单元测试与集成测试的构建。
\end{itemize}

系统运行流程可概括为：用户在 Streamlit 页面上传图像与音频，前端将文件暂存至临时目录并调用 \texttt{/api/v1/inference/hallo2} 创建任务；后端校验文件后在任务工作空间建立隔离目录并入队；TaskManager 触发后台线程执行 Hallo2Pipeline，StateManager 持续写入进度与 ETA；前端以 2 s 周期轮询 \texttt{/api/v1/tasks/\{task\_id\}} 获取状态，任务完成后通过 \texttt{/api/v1/tasks/\{task\_id\}/video} 拉取视频并展示预览。具体实现细节见第~\ref{sec:impl-frontend} 与第~\ref{sec:impl-backend} 节。

部署层面通过启动脚本统一拉起前后端：脚本负责环境初始化、服务就绪探测与异常回收，确保前端快速可用且后端模型加载可观测。具体脚本实现与参数配置见实现章节。

\subsubsection{展示层}

展示层采用 Streamlit 构建交互入口，强调快速迭代与端到端任务可视化。选择 Streamlit 的主要原因包括：

\begin{itemize}
    \item \textbf{开发效率}：可基于 Python 代码快速构建交互式应用，降低前端工程投入。
    \item \textbf{迭代便利}：支持热更新机制，便于在实验与原型阶段快速迭代交互流程。
    \item \textbf{组件完备}：内置上传、下载、进度条等常用组件，能够覆盖关键交互需求。
    \item \textbf{缓存机制}：支持 \texttt{@st.cache} 等缓存机制，便于复用中间结果与加速交互响应。
    \item \textbf{开源生态}：开源可用，便于部署与二次开发。
\end{itemize}

展示层面向用户提供统一入口，其功能设计可概括为：
\begin{itemize}
    \item \textbf{输入与校验}：多文件上传、格式检测与候选输入选择；
    \item \textbf{任务交互}：任务提交、进度条与状态提示（含 ETA）；
    \item \textbf{结果获取}：Recent Creations 预览、视频下载与缓存展示；
    \item \textbf{状态可视化}：后端健康度、队列状态与加载提示；
    \item \textbf{国际化能力}：多语言切换与配置持久化。
\end{itemize}
上述交互细节与界面布局的工程实现见 \ref{sec:impl-frontend} 节。

在默认部署配置下，展示层监听指定端口提供 Web 访问。前端通过 HTTP 客户端调用后端 API，并采用定时刷新与缓存窗口机制降低界面闪烁；具体实现细节见第~\ref{sec:impl-frontend} 节。

\subsubsection{API层}

API 层选择 FastAPI 框架实现 RESTful 接口，用于为前端交互与第三方集成提供统一的任务服务入口。选择 FastAPI 作为 API 框架的主要原因包括：

\begin{itemize}
    \item \textbf{高性能}：基于 ASGI 标准，具备良好的异步处理能力，可支撑高并发接入。
    \item \textbf{接口可用性}：采用自动化接口文档生成机制（Swagger UI / ReDoc），便于接口测试与快速集成。
    \item \textbf{数据验证}：集成 Pydantic，实现请求参数验证与类型约束，降低无效请求对系统的影响。
    \item \textbf{异步支持}：原生支持 \texttt{async/await}，便于与异步任务体系协同。
    \item \textbf{工程维护}：代码组织清晰，便于维护与扩展。
\end{itemize}

\paragraph{RESTful API 设计原则}

系统的API设计遵循以下RESTful原则：

\begin{enumerate}
    \item \textbf{资源导向}：URI表示资源而非操作，例如 \texttt{/api/v1/tasks} 表示任务资源
    \item \textbf{标准 HTTP 方法}：使用 GET 获取资源、POST 创建资源、DELETE 删除资源
    \item \textbf{版本控制}：使用 \texttt{/api/v1/} 路径前缀实现API版本管理
    \item \textbf{结构化响应}：以 JSON 承载任务状态、进度与错误信息
    \item \textbf{合理的 HTTP 状态码}：2xx/4xx/5xx 明确区分成功与失败原因
\end{enumerate}

\paragraph{核心API端点}

系统的核心API端点如表~\ref{tab:api_endpoints}所示。

\begin{table}[h]
    \centering
    \caption{系统核心API端点}
    \small
    \setlength{\tabcolsep}{4pt}
    \renewcommand{\arraystretch}{1.05}
    \begin{tabular}{|l|l|l|p{4cm}|}
        \hline
        \textbf{HTTP方法} & \textbf{端点} & \textbf{功能描述} & \textbf{主要参数/返回值} \\
        \hline
        GET & / & 根路径服务信息 & 服务名称、版本、状态 \\
        \hline
        GET & /health & 简单健康检查 & GPU可用性与设备信息 \\
        \hline
        GET & /api/v1/health & 详细系统状态 & GPU状态、已加载模型列表 \\
        \hline
        GET & /api/v1/models & 列出所有模型 & 返回注册模型及加载状态 \\
        \hline
        GET & /api/v1/models/\{name\} & 获取指定模型信息 & 返回模型元信息 \\
        \hline
        POST & /api/v1/inference/hallo2 & 提交推理任务 & 输入：图像、音频、use\_cache；返回 task\_id \\
        \hline
        POST & /api/v1/inference/hallo2/config & 更新推理配置 & 输入：配置参数；返回确认信息 \\
        \hline
        GET & /api/v1/tasks & 获取任务列表 & 返回任务字典与数量 \\
        \hline
        GET & /api/v1/tasks/recent & 获取最近完成任务 & 返回最近任务列表 \\
        \hline
        GET & /api/v1/tasks/\{task\_id\} & 查询任务状态 & 进度、状态、ETA、结果与错误 \\
        \hline
        GET & /api/v1/tasks/\{task\_id\}/video & 下载生成视频 & 返回 MP4 文件 \\
        \hline
        POST & /api/v1/tasks/\{task\_id\}/logs & 获取任务日志 & 返回任务日志文本 \\
        \hline
        DELETE & /api/v1/tasks/\{task\_id\} & 取消队列任务 & 返回取消成功确认 \\
        \hline
    \end{tabular}
\end{table}

\paragraph{接口约定}

推理任务提交采用 \texttt{multipart/form-data} 形式上传图像与音频，并支持 \texttt{use\_cache} 参数控制预处理缓存；后端保存输入文件后返回 \texttt{task\_id}、\texttt{status} 与 \texttt{message}。任务查询接口返回结构化的进度与状态信息（含 ETA），用于前端定时轮询与进度条更新。具体字段定义与序列化细节见 \ref{sec:impl-backend} 节。

\paragraph{数据验证}

API 层通过 Pydantic 对请求参数与响应结构进行类型约束与范围校验，以在接口入口处提前拦截无效输入，从而降低其对推理链路与资源占用的影响。

\paragraph{异常处理}

API 层实现全局异常处理器，以确保异常被统一捕获并返回一致的错误响应格式：

\begin{enumerate}
    \item \textbf{文件验证异常}：文件格式错误、大小超限等
    \item \textbf{参数验证异常}：由 Pydantic 自动捕获的参数验证错误
    \item \textbf{任务异常}：任务ID不存在、任务已取消等
    \item \textbf{系统异常}：GPU不可用、显存溢出等
    \item \textbf{未知异常}：捕获所有未预期的异常，防止服务崩溃
\end{enumerate}

综上，API 层设计为系统提供了高性能、模块化的任务接口体系，其端点组织结构如图~\ref{fig:api_endpoints}所示。

\begin{figure}[h]
    \centering
    \begin{tikzpicture}[
        scale=0.85,
        node distance=1.5cm,
        auto,
        endpoint/.style={rectangle, draw, thick, fill=cyan!20, minimum width=2.2cm,
                         minimum height=0.6cm, align=center, font=\tiny},
        method/.style={align=center, font=\tiny\bfseries},
        arrow/.style={->, thick}
    ]

    % 标题
    \node[align=center] at (4.5, 8.5) {\Large \textbf{FastAPI 端点架构}};

    % 健康检查组
    \node[method] at (1.5, 7.5) {健康检查};
    \node[endpoint, fill=green!30] (health1) at (1.5, 6.8) {GET /health};
    \node[endpoint, fill=green!30] (health2) at (1.5, 6) {GET /api/v1/health};

    % 推理端点组
    \node[method] at (4.5, 7.5) {推理任务};
    \node[endpoint, fill=blue!30] (inferencePost) at (4.5, 6.8) {POST /api/v1/inference/hallo2};
    \node[endpoint, fill=blue!30] (inferenceConfig) at (4.5, 6) {POST /api/v1/inference/hallo2/config};

    % 任务管理组
    \node[method] at (7.5, 7.5) {任务管理};
    \node[endpoint, fill=orange!30] (tasksList) at (7.5, 6.8) {GET /api/v1/tasks};
    \node[endpoint, fill=orange!30] (tasksRecent) at (7.5, 6) {GET /api/v1/tasks/recent};
    \node[endpoint, fill=orange!30] (taskStatus) at (7.5, 5.2) {GET /api/v1/tasks/\{id\}};

    % 模型端点组
    \node[method] at (10.5, 7.5) {模型信息};
    \node[endpoint, fill=purple!30] (modelsList) at (10.5, 6.8) {GET /api/v1/models};
    \node[endpoint, fill=purple!30] (modelInfo) at (10.5, 6) {GET /api/v1/models/\{name\}};

    % 结果下载
    \node[method] at (4.5, 4.5) {结果下载};
    \node[endpoint, fill=red!30] (downloadVideo) at (4.5, 3.8) {GET /api/v1/tasks/\{id\}/video};
    \node[endpoint, fill=red!30] (downloadLogs) at (4.5, 3) {POST /api/v1/tasks/\{id\}/logs};

    % 删除操作
    \node[endpoint, fill=red!30] (deleteTask) at (7.5, 3.8) {DELETE /api/v1/tasks/\{id\}};

    % 数据流向箭头
    \draw[arrow] (inferencePost) -- (4.5, 5.6);
    \node[align=center, font=\tiny] at (3.5, 5.6) {提交};

    \draw[arrow] (4.5, 5.6) -- (taskStatus);
    \node[align=center, font=\tiny] at (5.5, 5.4) {查询};

    \draw[arrow] (taskStatus) -- (downloadVideo);
    \node[align=center, font=\tiny] at (6.5, 4.5) {下载};

    \draw[arrow, dashed] (tasksRecent) |- (downloadVideo);
    \node[align=center, font=\tiny] at (6.2, 4.9) {最近结果};

    \end{tikzpicture}
    \caption{FastAPI 端点架构和数据流}
    \label{fig:api_endpoints}
\end{figure}


\subsubsection{服务层}

服务层在系统架构中承担业务逻辑与资源调度的核心职能，其设计目标是构建松耦合的任务调度与状态管理机制，并为模型推理提供统一的资源治理入口。服务层主要由三个关键模块构成：

\paragraph{TaskManager（任务队列管理）}

TaskManager 用于管理推理任务的全生命周期，并以生产者--消费者模式组织任务的创建、排队与执行：

\begin{itemize}
    \item \textbf{任务队列}：基于 \texttt{queue.Queue} 维护线程安全队列。
    \item \textbf{后台线程}：以守护线程方式异步执行任务函数。
    \item \textbf{并发控制}：通过 \texttt{current\_tasks} 计数与锁控制并发，默认单任务串行。
    \item \textbf{任务取消}：支持取消队列中未执行任务，运行中任务不支持强制中断。
    \item \textbf{优雅关闭}：关闭时等待当前任务结束，避免状态不一致。
\end{itemize}

\paragraph{StateManager（状态管理）}

StateManager 用于维护任务状态与进度信息，为前端提供可观测的实时反馈。任务状态转移关系如图~\ref{fig:task_state_machine}所示。

\begin{figure}[h]
    \centering
    \begin{tikzpicture}[
        scale=1,
        node distance=2cm,
        auto,
        state/.style={circle, draw, thick, minimum width=1.5cm, align=center},
        transition/.style={->, thick, bend left},
        font=\small
    ]

    % 标题
    \node[align=center] at (3.5, 4.5) {\large \textbf{任务生命周期状态机}};

    % 状态节点
    \node[state, fill=yellow!40] (pending) at (1, 2.5) {\shortstack{Pending\\(等待)}};
    \node[state, fill=cyan!40] (running) at (3.5, 2.5) {\shortstack{Processing\\(运行)}};
    \node[state, fill=green!40] (completed) at (6, 2.5) {\shortstack{Completed\\(完成)}};
    \node[state, fill=red!40] (failed) at (6, 0.5) {\shortstack{Failed\\(失败)}};

    % 状态转移
    \draw[transition] (pending) to node[above] {submit} (running);
    \draw[transition] (running) to node[above] {success} (completed);
    \draw[transition] (running) to node[right] {error} (failed);
    \draw[transition] (pending) to node[left] {cancel} (failed);

    % 说明文字
    \node[align=center, font=\tiny] at (1, 1.5) {\shortstack{API已接受\\等待执行}};
    \node[align=center, font=\tiny] at (3.5, 1.5) {\shortstack{推理进行中\\实时更新进度}};
    \node[align=center, font=\tiny] at (6, 1.5) {\shortstack{视频已生成\\可下载}};
    \node[align=center, font=\tiny] at (6, -0.5) {\shortstack{推理失败\\保存错误日志}};

    \end{tikzpicture}
    \caption{任务生命周期状态机}
    \label{fig:task_state_machine}
\end{figure}

主要功能包括：

\begin{itemize}
    \item \textbf{任务状态}：\texttt{pending/processing/completed/failed} 四态流转
    \item \textbf{进度与ETA}：记录 0--100\% 进度，并基于耗时估算 \texttt{estimated\_remaining\_time}
    \item \textbf{元数据}：维护 \texttt{created\_at}、\texttt{started\_at}、\texttt{updated\_at} 与结果字段
    \item \textbf{错误记录}：任务失败时记录 \texttt{error} 与状态消息
    \item \textbf{线程安全}：使用 \texttt{threading.RLock} 保护并发访问
    \item \textbf{近期结果}：维护最近完成任务列表（默认 10 条）供前端展示
\end{itemize}

\paragraph{ModelRegistry（模型注册表）}

ModelRegistry实现了Plugin模式，支持灵活的模型扩展：

\begin{itemize}
    \item \textbf{模型注册}：支持通过装饰器或配置文件注册新的模型
    \item \textbf{延迟加载}：模型仅在首次调用时从磁盘加载到内存和GPU，减少启动时间
    \item \textbf{实例缓存}：已加载的模型实例保存在内存中，后续请求直接返回缓存实例
    \item \textbf{模型卸载}：显式卸载模型并触发 \texttt{torch.cuda.empty\_cache()} 回收显存
    \item \textbf{模型信息}：提供模型元信息查询接口，供 \texttt{/api/v1/models} 调用
\end{itemize}

\subsubsection{推理层}

推理层承载 Hallo2 推理管道的核心流程编排。为提高流程可解释性与模块可替换性，本研究将推理过程组织为三阶段结构：预处理、推理与后处理。

\paragraph{预处理阶段（Preprocessing）}

预处理阶段对输入的图像和音频进行处理，为推理准备数据：

\begin{enumerate}
    \item \textbf{图像预处理}
    \begin{itemize}
        \item 人脸检测：基于 InsightFace 的 \texttt{FaceAnalysis} 检测人脸框，默认取最大人脸
        \item 掩码生成：生成 face/lip/background 掩码，支持缓存复用
        \item 特征提取：提取人脸 embedding 作为身份条件输入
        \item 数据变换：完成尺度归一化与多尺度掩码展开
    \end{itemize}

    \item \textbf{音频预处理}
    \begin{itemize}
        \item 音频加载与重采样：统一采样率为 16 kHz
        \item 可选人声分离：通过 \texttt{audio\_separator} 模型分离人声轨道
        \item 特征提取：基于 Wav2Vec2 提取音频嵌入并按 FPS 对齐
        \item 长音频切分：支持按片段切分并拼接嵌入序列
    \end{itemize}

    \item \textbf{数据准备}
    \begin{itemize}
        \item 批次维度补齐：统一张量维度以匹配推理接口
        \item 缓存目录：中间结果写入任务工区，便于复用与调试
        \item 维度校验：确保音频嵌入与帧数一致
    \end{itemize}
\end{enumerate}

\paragraph{推理阶段（Inference）}

推理阶段使用预训练的 Hallo2 模型生成视频序列。如图~\ref{fig:hallo2_pipeline}所示，完整推理过程包括以下主要模型组件：

\begin{figure}[h]
    \centering
    \begin{tikzpicture}[
        scale=1,
        node distance=2cm,
        auto,
        stageBox/.style={rectangle, draw, thick, fill=blue!20, minimum width=2.2cm,
                          minimum height=1cm, align=center},
        processBox/.style={rectangle, draw, fill=green!20, minimum width=1.8cm,
                            minimum height=0.5cm, align=center, font=\tiny},
        arrow/.style={->, thick, line width=1.5pt}
    ]

    % 标题
    \node[align=center] at (6, 5.5) {\Large \textbf{Hallo2 推理管道三阶段流程}};

    % 输入
    \node at (0.8, 4) {\textbf{输入}};
    \node[processBox] (img) at (0.8, 3.3) {人物图像};
    \node[processBox] (audio) at (0.8, 2.5) {音频文件};

    % 阶段1：预处理
    \node[stageBox, fill=cyan!30] (stage1) at (3, 3) {\textbf{预处理}（Preprocessing）};
    \node[processBox, fill=cyan!20] at (3, 1.8) {\shortstack{人脸检测\\掩码生成}};
    \node[processBox, fill=cyan!20] at (3, 1.2) {\shortstack{音频分离\\特征提取}};

    % 箭头
    \draw[arrow] (img) -- (1.8, 3);
    \draw[arrow] (audio) -- (1.8, 2.5);
    \draw[arrow] (1.8, 3) -- (3, 3);

    % 阶段2：推理
    \node[stageBox, fill=orange!30] (stage2) at (6, 3) {\textbf{推理}（Inference）};
    \node[processBox, fill=orange!20] at (6, 1.8) {\shortstack{VAE编码\\条件融合}};
    \node[processBox, fill=orange!20] at (6, 1.2) {\shortstack{扩散逆向\\生成视频}};

    \draw[arrow] (stage1) -- (stage2);

    % 阶段3：后处理
    \node[stageBox, fill=red!30] (stage3) at (9, 3) {\textbf{后处理}（Postprocessing）};
    \node[processBox, fill=red!20] at (9, 1.8) {\shortstack{VAE解码\\视频编码}};
    \node[processBox, fill=red!20] at (9, 1.2) {\shortstack{音频混合\\文件输出}};

    \draw[arrow] (stage2) -- (stage3);

    % 输出
    \node at (11.2, 3) {\textbf{输出}};
    \draw[arrow] (stage3) -- (11.2, 3.3);
    \node[processBox, fill=green!40] at (11.2, 2.5) {MP4视频文件};

    \end{tikzpicture}
    \caption{Hallo2 推理管道三阶段流程（预处理-推理-后处理）}
    \label{fig:hallo2_pipeline}
\end{figure}

\begin{enumerate}
    \item \textbf{模型组件}
    \begin{itemize}
        \item \textbf{VAE（变分自编码器）}：在潜空间进行图像/视频编解码
        \item \textbf{Reference UNet2D}：以参考图像为条件编码身份信息
        \item \textbf{Denoising UNet3D}：进行时序去噪以生成连续视频帧
        \item \textbf{Motion Module}：注入音频驱动的运动信息
        \item \textbf{FaceLocator/MaskPredictUNet}：定位与预测人脸/口型掩码
    \end{itemize}

    \item \textbf{推理过程}
    \begin{itemize}
        \item 条件编码：参考图像与音频特征共同驱动生成
        \item 分片推理：按 \texttt{n\_sample\_frames} 分段生成并串接输出
        \item 掩码引导：MaskPredictUNet 预测人脸与口型区域，抑制非目标区域扰动
        \item 进度回调：推理过程通过回调更新进度与状态信息
    \end{itemize}

    \item \textbf{GPU优化}
    \begin{itemize}
        \item 统一精度：GPU 可用时默认采用 \texttt{float16}
        \item 模型常驻：全局模型实例在启动阶段加载并复用
        \item 显存回收：模型卸载触发 \texttt{torch.cuda.empty\_cache()}
    \end{itemize}
\end{enumerate}

\paragraph{后处理阶段（Postprocessing）}

后处理阶段将模型输出转换为最终的视频文件：

\begin{enumerate}
    \item \textbf{视频合成}
    \begin{itemize}
        \item VAE 解码：将潜空间结果还原为 RGB 帧序列
        \item 帧序列整合：按 clip 顺序拼接并生成连续视频
        \item 视频编码：通过 PyAV/FFmpeg 生成 MP4 格式视频
    \end{itemize}

    \item \textbf{音频处理}
    \begin{itemize}
        \item 音频合流：若任务存在音频输入，则与视频合并输出
        \item 无音频降级：音频缺失时输出纯视频以保证任务可完成
    \end{itemize}

    \item \textbf{文件输出}
    \begin{itemize}
        \item 输出隔离：保存到任务独立工作空间，避免任务间资源冲突
        \item 结果返回：将视频文件路径写入任务 \texttt{result} 字段供下载接口使用
    \end{itemize}
\end{enumerate}

\subsubsection{模型层}

模型层集成了深度学习框架和预训练模型，为上层推理提供计算基础。

\paragraph{深度学习框架}

系统基于以下框架构建：

\begin{itemize}
    \item \textbf{PyTorch 2.1.1}：核心深度学习框架，提供张量计算和自动求导功能
    \item \textbf{NVIDIA CUDA 12.x}：GPU并行计算平台，提供GPU加速
    \item \textbf{cuDNN}：CUDA深度神经网络库，提供高效的卷积、激活函数等操作
    \item \textbf{Diffusers}：Hugging Face官方的扩散模型库，提供各种预训练扩散模型
    \item \textbf{Transformers}：Hugging Face官方的变换器模型库，提供预训练的语言和多模态模型
\end{itemize}

\paragraph{预训练模型}

系统集成的主要预训练模型包括：

\begin{enumerate}
    \item \textbf{Hallo2 子模块}
    \begin{itemize}
        \item VAE（\texttt{AutoencoderKL}）：视频帧潜空间编解码
        \item Reference UNet2D：编码参考图像身份与风格
        \item Denoising UNet3D + Motion Module：时序去噪与运动建模
        \item FaceLocator：面部区域定位与条件约束
        \item ImageProj/AudioProj：图像与音频条件映射
        \item MaskPredictUNet：人脸/口型掩码预测
    \end{itemize}

    \item \textbf{音频与视觉特征模型}
    \begin{itemize}
        \item Wav2Vec2：音频驱动特征提取
        \item InsightFace FaceAnalysis：人脸检测与 embedding 提取
        \item audio\_separator：可选人声分离模型
    \end{itemize}
\end{enumerate}

\paragraph{GPU设备管理}

系统实现了较为完善的 GPU 设备与显存管理机制。如图~\ref{fig:gpu_memory_management}所示，从 GPU 检测到显存释放的完整流程包括：

\begin{figure}[h]
    \centering
    \begin{tikzpicture}[
        scale=0.85,
        node distance=1.2cm,
        auto,
        memoryBox/.style={rectangle, draw, thick, fill=green!20, minimum width=2.2cm,
                           minimum height=0.55cm, align=center, font=\tiny},
        controlBox/.style={rounded rectangle, draw, thick, fill=orange!20,
                            minimum width=2cm, minimum height=0.5cm, align=center, font=\tiny},
        arrow/.style={->, thick}
    ]

    % 标题
    \node[align=center] at (5, 7.5) {\Large \textbf{GPU 内存管理流程}};

    % 上行：模型加载
    \node[controlBox] (detectGpu) at (2, 6.5) {检测GPU};
    \node[memoryBox] (allocate) at (2, 5.5) {分配显存};
    \node[controlBox] (lazyLoad) at (2, 4.5) {延迟加载};
    \node[memoryBox] (modelLoaded) at (2, 3.5) {模型已加载};

    \draw[arrow] (detectGpu) -- (allocate);
    \draw[arrow] (allocate) -- (lazyLoad);
    \draw[arrow] (lazyLoad) -- (modelLoaded);

    % 中间：推理执行
    \node[controlBox] (inference) at (5, 5.5) {执行推理};
    \node[memoryBox] (tempMemory) at (5, 4.5) {临时显存占用};
    \node[controlBox] (monitor) at (5, 3.5) {监控占用};

    \draw[arrow] (modelLoaded) -- (inference);
    \draw[arrow] (inference) -- (tempMemory);
    \draw[arrow] (tempMemory) -- (monitor);

    % 下行：内存管理
    \node[controlBox] (precision) at (8, 6.5) {多精度支持};
    \node[memoryBox] (floatType) at (8, 5.5) {float32/16};
    \node[controlBox] (checkpoint) at (8, 4.5) {缓存回收};
    \node[memoryBox] (optimize) at (8, 3.5) {显存优化};

    \draw[arrow] (precision) -- (floatType);
    \draw[arrow] (floatType) -- (checkpoint);
    \draw[arrow] (checkpoint) -- (optimize);

    % 清理阶段
    \node[controlBox] (cleanup) at (5, 2) {执行清理};
    \node[memoryBox] (release) at (5, 0.8) {释放显存};

    \draw[arrow] (monitor) -- (cleanup);
    \draw[arrow] (optimize) -- (cleanup);
    \draw[arrow] (cleanup) -- (release);

    \end{tikzpicture}
    \caption{GPU 显存管理流程}
    \label{fig:gpu_memory_management}
\end{figure}

\begin{enumerate}
    \item \textbf{设备检测}
    \begin{itemize}
        \item 启动阶段检查 \texttt{torch.cuda.is\_available()} 与 GPU 数量
        \item 通过 \texttt{CUDA\_VISIBLE\_DEVICES} 指定目标 GPU
        \item 健康检查接口返回设备名称与可用性
    \end{itemize}

    \item \textbf{显存管理}
    \begin{itemize}
        \item 模型卸载时调用 \texttt{torch.cuda.empty\_cache()} 释放缓存
        \item 通过单任务并发降低显存峰值
        \item 任务目录隔离输入输出，避免无效占用
    \end{itemize}

    \item \textbf{精度管理}
    \begin{itemize}
        \item GPU 可用时默认使用 \texttt{float16}，CPU 回退为 \texttt{float32}
        \item 通过配置可切换精度策略以权衡速度与稳定性
    \end{itemize}

    \item \textbf{多GPU支持}
    \begin{itemize}
        \item 通过环境变量选择指定 GPU
        \item 预留多 GPU 扩展接口，当前以单 GPU 为默认部署
    \end{itemize}

    \item \textbf{性能监控}
    \begin{itemize}
        \item 记录模型加载与推理过程日志
        \item 健康检查接口输出设备状态便于外部监控
    \end{itemize}
\end{enumerate}

\subsection{模块设计}

本小节详细说明系统的各主要模块及其设计。各模块之间的关系如图~\ref{fig:module_dependency}所示。

\begin{figure}[h]
    \centering
    \begin{tikzpicture}[
        scale=0.9,
        node distance=1.5cm,
        auto,
        module/.style={rectangle, draw, thick, fill=blue!20, minimum width=1.5cm,
                       minimum height=0.6cm, align=center, font=\small},
        core/.style={rectangle, draw, thick, fill=red!30, minimum width=1.8cm,
                     minimum height=0.6cm, align=center, font=\small},
        dependency/.style={->, thick, dashed},
        arrow/.style={->, thick}
    ]

    % 标题
    \node[align=center] at (4.5, 7.5) {\Large \textbf{核心模块依赖关系}};

    % 核心模块
    \node[core] (api) at (1.5, 6) {\shortstack{FastAPI\\App}};
    \node[module] (taskMgr) at (1.5, 4.5) {TaskManager};
    \node[module] (stateMgr) at (4.5, 4.5) {StateManager};
    \node[module] (modelReg) at (7.5, 4.5) {ModelRegistry};

    % 推理模块
    \node[module] (pipeline) at (4.5, 3) {Hallo2Pipeline};

    % 处理器模块
    \node[module] (imgProc) at (1.5, 1.5) {ImageProcessor};
    \node[module] (audioProc) at (4.5, 1.5) {AudioProcessor};
    \node[module] (maskProc) at (7.5, 1.5) {MaskProcessor};

    % 依赖关系
    \draw[arrow] (api) -- (taskMgr);
    \draw[arrow] (api) -- (stateMgr);
    \draw[arrow] (taskMgr) -- (stateMgr);
    \draw[arrow] (taskMgr) -- (modelReg);

    \draw[arrow] (taskMgr) -- (pipeline);
    \draw[arrow] (modelReg) -- (pipeline);

    \draw[arrow] (pipeline) -- (imgProc);
    \draw[arrow] (pipeline) -- (audioProc);
    \draw[arrow] (pipeline) -- (maskProc);

    % 说明
    \node[font=\tiny, align=center] at (1.5, 0.5) {\shortstack{图像\\预处理}};
    \node[font=\tiny, align=center] at (4.5, 0.5) {\shortstack{音频\\预处理}};
    \node[font=\tiny, align=center] at (7.5, 0.5) {\shortstack{掩码\\处理}};

    \end{tikzpicture}
    \caption{系统核心模块依赖关系}
    \label{fig:module_dependency}
\end{figure}

其中，系统核心模块及其关系如表~\ref{tab:module_relations}所示。

\begin{table}[h]
    \centering
    \caption{系统核心模块及其关系}
    \small
    \begin{tabular}{|l|l|l|}
        \hline
        \textbf{模块名称} & \textbf{主要职责} & \textbf{依赖模块} \\
        \hline
        FastAPI App & HTTP请求处理、路由管理 & TaskManager、StateManager \\
        \hline
        TaskManager & 任务队列、并发控制、后台执行 & StateManager、ModelRegistry \\
        \hline
        StateManager & 状态追踪、进度管理、元数据存储 & 无 \\
        \hline
        ModelRegistry & 模型注册、加载、缓存 & 无 \\
        \hline
        Hallo2Pipeline & 推理管道执行 & ModelRegistry、ImageProcessor等 \\
        \hline
        ImageProcessor & 图像预处理 & 无 \\
        \hline
        AudioProcessor & 音频预处理 & 无 \\
        \hline
        MaskProcessor & 掩码处理 & ImageProcessor \\
        \hline
    \end{tabular}
\end{table}

\subsubsection{关键数据结构}

系统的关键数据结构包括：

\begin{enumerate}
    \item \textbf{Task}：任务对象
    \begin{itemize}
        \item task\_id：任务唯一标识
        \item status：任务状态（pending/processing/completed/failed）
        \item progress：进度百分比（0--100）
        \item status\_message：阶段说明文本
        \item created\_at、started\_at、updated\_at：时间戳
        \item estimated\_remaining\_time：估算剩余时间（秒）
        \item result、error：结果字典与错误信息
    \end{itemize}

    \item \textbf{TaskStatus}：任务状态对象
    \begin{itemize}
        \item status：当前状态
        \item progress：进度百分比
        \item status\_message：当前阶段说明
        \item estimated\_remaining\_time：剩余时间估计
        \item result：结果信息（含视频路径）
        \item error：失败原因（仅失败时返回）
    \end{itemize}

    \item \textbf{Model}：模型对象
    \begin{itemize}
        \item name：模型名称
        \item initialized：是否已加载
        \item version：模型版本
        \item device、dtype：推理设备与精度
    \end{itemize}
\end{enumerate}

\section{技术栈选型与架构模式}
\label{sec:tech-stack}

\subsection{关键技术选型的 Trade-off 分析}

系统在前端框架、后端框架、任务调度与模型管理等关键环节需权衡性能、开发效率、部署成本与生态完善度。以下从四个维度对比备选方案,说明最终选型的理由。

\subsubsection{前端框架选型}

\begin{table}[h]
    \centering
    \caption{前端框架对比}
    \label{tab:frontend-compare}
    \small
    \begin{tabular}{l|l|l|l}
        \hline
        方案 & 优势 & 劣势 & 适用场景 \\
        \hline
        \textbf{Streamlit} (选用) &
        \begin{tabular}[t]{@{}l@{}}Python编写,学习成本低\\内置上传/进度条组件\\热更新,迭代快\end{tabular} &
        \begin{tabular}[t]{@{}l@{}}定制化受限\\全页刷新开销大\\(已用Fragment缓解)\end{tabular} &
        \begin{tabular}[t]{@{}l@{}}原型验证\\内部工具\end{tabular} \\
        \hline
        React + Ant Design &
        \begin{tabular}[t]{@{}l@{}}UI灵活\\局部刷新性能好\end{tabular} &
        \begin{tabular}[t]{@{}l@{}}需前端工程师\\开发周期长\end{tabular} &
        \begin{tabular}[t]{@{}l@{}}To C产品\\高定制需求\end{tabular} \\
        \hline
        Gradio &
        \begin{tabular}[t]{@{}l@{}}机器学习场景优化\\支持排队机制\end{tabular} &
        \begin{tabular}[t]{@{}l@{}}布局控制弱\\难以集成复杂逻辑\end{tabular} &
        \begin{tabular}[t]{@{}l@{}}模型Demo\\快速分享\end{tabular} \\
        \hline
    \end{tabular}
\end{table}

\noindent \textbf{选型结论}: 本系统优先快速迭代与低开发成本,选择 Streamlit;未来若需面向 C 端用户可迁移至 React,后端接口无需变更。

\subsubsection{后端框架选型}

\begin{table}[h]
    \centering
    \caption{后端框架对比}
    \label{tab:backend-compare}
    \small
    \begin{tabular}{l|l|l|l}
        \hline
        方案 & 优势 & 劣势 & 性能 \\
        \hline
        \textbf{FastAPI} (选用) &
        \begin{tabular}[t]{@{}l@{}}异步高性能(基于ASGI)\\自动生成OpenAPI文档\\Pydantic类型校验\end{tabular} &
        \begin{tabular}[t]{@{}l@{}}生态较Flask小\end{tabular} &
        \begin{tabular}[t]{@{}l@{}}异步接口\\QPS$>$1000\end{tabular} \\
        \hline
        Flask + Celery &
        \begin{tabular}[t]{@{}l@{}}生态成熟\\插件丰富\end{tabular} &
        \begin{tabular}[t]{@{}l@{}}WSGI同步阻塞\\需额外引入Celery队列\end{tabular} &
        \begin{tabular}[t]{@{}l@{}}同步接口\\QPS$\sim$500\end{tabular} \\
        \hline
        Django &
        \begin{tabular}[t]{@{}l@{}}全栈框架\\ORM内置\end{tabular} &
        \begin{tabular}[t]{@{}l@{}}重量级,启动慢\\对机器学习场景冗余\end{tabular} &
        \begin{tabular}[t]{@{}l@{}}适合Web应用\\非机器学习服务\end{tabular} \\
        \hline
    \end{tabular}
\end{table}

\noindent \textbf{选型结论}: FastAPI 的异步能力可支撑高并发文件上传与状态查询;自动文档降低前端对接成本;Pydantic 在编译时捕获类型错误,减少运行时异常。

\subsubsection{任务调度机制选型}

\begin{table}[h]
    \centering
    \caption{任务调度方案对比}
    \label{tab:queue-compare}
    \small
    \begin{tabular}{l|l|l|l}
        \hline
        方案 & 优势 & 劣势 & 部署依赖 \\
        \hline
        \textbf{queue.Queue} (选用) &
        \begin{tabular}[t]{@{}l@{}}标准库,无外部依赖\\线程安全\\阻塞式消费,逻辑简单\end{tabular} &
        \begin{tabular}[t]{@{}l@{}}单进程内有效\\不支持分布式\end{tabular} &
        无 \\
        \hline
        Celery + Redis &
        \begin{tabular}[t]{@{}l@{}}分布式任务队列\\支持多worker\end{tabular} &
        \begin{tabular}[t]{@{}l@{}}需部署Redis\\配置复杂\end{tabular} &
        Redis \\
        \hline
        asyncio.Queue &
        \begin{tabular}[t]{@{}l@{}}协程原生支持\\轻量级\end{tabular} &
        \begin{tabular}[t]{@{}l@{}}与线程模型不兼容\\推理库多为同步调用\end{tabular} &
        无 \\
        \hline
    \end{tabular}
\end{table}

\noindent \textbf{选型结论}: 当前系统部署于单机单 GPU,选择 \texttt{queue.Queue} 可避免引入外部依赖;未来若需多机推理可迁移至 Celery,任务提交接口无需变更。

\subsection{已选技术栈总览}

基于上述分析,系统最终采用的技术栈如表~\ref{tab:tech_stack}所示。

\begin{table}[h]
    \centering
    \caption{系统关键技术栈总览}
    \label{tab:tech_stack}
    \small
    \begin{tabular}{l|l|l}
        \hline
        \textbf{技术层} & \textbf{选择方案} & \textbf{版本} \\
        \hline
        前端框架 & Streamlit & 1.20+ \\
        Web框架 & FastAPI & 0.100+ \\
        ASGI服务器 & Uvicorn & 0.20+ \\
        数据验证 & Pydantic & 2.x \\
        任务队列 & queue.Queue & 标准库 \\
        深度学习 & PyTorch & 2.x \\
        扩散模型库 & Diffusers & 0.24+ \\
        人脸检测 & InsightFace & 0.7+ \\
        音频特征 & Wav2Vec2 (transformers) & 4.x \\
        视频处理 & PyAV + MoviePy & 1.x \\
        日志系统 & logging + loguru & 标准库 \\
        \hline
    \end{tabular}
\end{table}

\subsubsection{架构设计模式}

系统的架构设计采用了多种经典的软件设计模式，以提高代码的可维护性和扩展性：

\begin{enumerate}
    \item \textbf{Plugin模式}
    \begin{itemize}
        \item 用于模型的灵活注册和扩展
        \item 支持添加新的AI模型而无需修改核心代码
        \item 实现方式：通过装饰器或配置文件注册模型，ModelRegistry统一管理
    \end{itemize}

    \item \textbf{生产者-消费者模式}
    \begin{itemize}
        \item API端点作为生产者提交任务，后台线程作为消费者执行推理
        \item 使用线程安全的队列（queue.Queue）解耦前后端
        \item 提高系统的并发处理能力
    \end{itemize}

    \item \textbf{单例化全局实例}
    \begin{itemize}
        \item ModelRegistry、TaskManager 与全局模型实例在进程内唯一
        \item 避免重复加载权重导致的显存浪费
    \end{itemize}

    \item \textbf{注册表/工厂模式}
    \begin{itemize}
        \item ModelRegistry充当工厂角色，统一创建和管理模型实例
        \item 支持延迟创建（延迟加载）
        \item 便于模型版本切换和更新
    \end{itemize}

    \item \textbf{配置驱动策略}
    \begin{itemize}
        \item 通过配置切换音频分离、掩码预测与精度策略
        \item 预留扩展位以适配不同硬件环境
    \end{itemize}

    \item \textbf{回调模式}
    \begin{itemize}
        \item 推理阶段以回调更新进度与状态信息
        \item 前端通过轮询获取状态，实现轻量可视化
    \end{itemize}
\end{enumerate}

\subsubsection{系统工作流程}

系统的完整工作流程如图~\ref{fig:complete_data_flow}和图~\ref{fig:system_sequence}所示。

\begin{figure}[h]
    \centering
    \begin{tikzpicture}[
        scale=0.8,
        node distance=1.5cm,
        auto,
        font=\small,
        flowBox/.style={rectangle, draw, thick, minimum width=2.5cm, minimum height=0.6cm,
                         align=center},
        process/.style={rounded rectangle, draw, thick, minimum width=2.5cm,
                        minimum height=0.6cm, align=center},
        arrow/.style={->, thick}
    ]

    % 第一行：用户和前端
    \node[flowBox, fill=cyan!20] (user) at (1, 7) {用户};
    \node[process, fill=cyan!30] (upload) at (1, 5.5) {\shortstack{上传图像\\和音频}};

    % 第二行：前端处理
    \node[process, fill=green!30] (validate) at (1, 4) {\shortstack{参数验证\\文件检查}};
    \node[process, fill=green!30] (request) at (3.5, 4) {\shortstack{HTTP POST\\请求}};

    % 第三行：API 层
    \node[process, fill=yellow!30] (apiProcess) at (3.5, 2.5) {\shortstack{API 验证\\创建任务}};
    \node[process, fill=yellow!30] (queue) at (6, 2.5) {\shortstack{加入\\任务队列}};

    % 第四行：后台处理
    \node[process, fill=orange!30] (preprocess) at (1.5, 1) {预处理};
    \node[process, fill=orange!30] (inference) at (3.5, 1) {推理};
    \node[process, fill=orange!30] (postprocess) at (5.5, 1) {后处理};

    % 第五行：输出
    \node[process, fill=red!30] (save) at (3.5, -0.5) {保存视频};
    \node[flowBox, fill=cyan!20] (download) at (5.5, -0.5) {用户下载};

    % 连接箭头
    \draw[arrow] (user) -- (upload);
    \draw[arrow] (upload) -- (validate);
    \draw[arrow] (validate) -- (request);
    \draw[arrow] (request) -- (apiProcess);
    \draw[arrow] (apiProcess) -- (queue);
    \draw[arrow] (queue) -- (preprocess);
    \draw[arrow] (preprocess) -- (inference);
    \draw[arrow] (inference) -- (postprocess);
    \draw[arrow] (postprocess) -- (save);
    \draw[arrow] (save) -- (download);

    % 回程箭头（实时更新）
    \draw[dashed, arrow] (queue.north) -- (1.5, 3) -- (1, 3.5);
    \node[font=\tiny] at (0.5, 3.2) {轮询};

    \node[align=center] at (3.5, 8) {\textbf{完整的数据流程}};

    \end{tikzpicture}
    \caption{用户请求到视频输出的完整数据流程}
    \label{fig:complete_data_flow}
\end{figure}
\begin{figure}[h]
    \centering
    \begin{tikzpicture}[
        scale=0.8,
        node distance=1cm,
        auto,
        participant/.style={rectangle, draw, thick, minimum width=1.5cm, align=center, font=\small},
        lifeline/.style={dashed},
        message/.style={->, thick},
        arrow/.style={->, thick}
    ]

    % 标题
    \node[align=center] at (6, 8.5) {\Large \textbf{系统交互时序图}};

    % 参与者
    \node[participant, fill=cyan!20] (user) at (1, 7.5) {用户};
    \node[participant, fill=green!20] (frontend) at (3, 7.5) {前端};
    \node[participant, fill=yellow!20] (api) at (5, 7.5) {API};
    \node[participant, fill=orange!20] (backend) at (7, 7.5) {后端};
    \node[participant, fill=red!20] (gpu) at (9, 7.5) {GPU};

    % 生命线
    \draw[lifeline] (1, 7) -- (1, 0.5);
    \draw[lifeline] (3, 7) -- (3, 0.5);
    \draw[lifeline] (5, 7) -- (5, 0.5);
    \draw[lifeline] (7, 7) -- (7, 0.5);
    \draw[lifeline] (9, 7) -- (9, 0.5);

    % 交互步骤
    \draw[message] (1, 6.5) -- (3, 6.3) node[midway, above, font=\tiny] {1. 上传文件};
    \draw[message] (3, 5.9) -- (5, 5.7) node[midway, above, font=\tiny] {2. 验证};
    \draw[message] (5, 5.3) -- (7, 5.1) node[midway, above, font=\tiny] {3. 创建任务};
    \draw[message] (5, 4.7) -- (3, 4.5) node[midway, above, font=\tiny] {4. 返回ID};

    \draw[message] (7, 4.1) -- (9, 3.9) node[midway, above, font=\tiny] {5. 推理执行};

    \draw[message, dashed] (3, 3.5) -- (5, 3.3) node[midway, above, font=\tiny] {6. 轮询进度};
    \draw[message, dashed] (5, 2.9) -- (3, 2.7) node[midway, above, font=\tiny] {7. 返回进度};

    \draw[message] (3, 2.3) -- (1, 2.1) node[midway, above, font=\tiny] {8. 更新UI};

    \draw[message] (9, 1.7) -- (7, 1.5) node[midway, above, font=\tiny] {9. 推理完成};
    \draw[message] (7, 1.1) -- (5, 0.9) node[midway, above, font=\tiny] {10. 返回结果};

    \end{tikzpicture}
    \caption{系统完整交互时序图}
    \label{fig:system_sequence}
\end{figure}

具体的执行步骤包括：

\begin{enumerate}
    \item 用户在 Streamlit 界面上传图像与音频并选择输入组合
    \item 前端将文件暂存至临时目录，提交 \texttt{/api/v1/inference/hallo2}
    \item 后端验证文件格式，生成 \texttt{task\_id} 并创建任务隔离空间
    \item 输入写入任务工作空间，TaskManager 创建任务并入队
    \item StateManager 初始化状态为 \texttt{pending}，队列空闲后进入 \texttt{processing}
    \item Hallo2Pipeline 执行预处理、推理与后处理，并通过回调更新进度
    \item 前端以 2 s 间隔轮询 \texttt{/api/v1/tasks/\{task\_id\}}，展示进度与 ETA
    \item 完成后生成视频文件，状态更新为 \texttt{completed} 或 \texttt{failed}
    \item 前端刷新 Recent Creations（\texttt{/api/v1/tasks/recent}）
    \item 用户通过 \texttt{/api/v1/tasks/\{task\_id\}/video} 下载并预览结果
\end{enumerate}

\section{本章小结}
\label{sec:design-summary}

本章从需求约束出发,给出 Emo Hallo 系统的架构设计与技术选型理由。系统采用分层 C/S 架构,核心设计决策包括:

\begin{enumerate}
    \item \textbf{异步解耦}: 前端通过 HTTP 提交任务后立即返回,后端队列异步调度推理,避免长时推理阻塞交互界面。
    \item \textbf{并发约束}: 任务队列配合 \texttt{max\_concurrent\_tasks=1} 串行化推理,防止 GPU 显存溢出(Hallo2 模型需 8--12GB + 推理时 4--6GB)。
    \item \textbf{模型预加载}: 启动阶段一次性加载模型权重(耗时约 12 分钟),后续任务复用全局实例,避免冷启动。
    \item \textbf{技术选型}: 前端选择 Streamlit 优先快速迭代,后端选择 FastAPI 利用异步性能,队列选择 \texttt{queue.Queue} 避免外部依赖。
\end{enumerate}

上述设计在单机单 GPU 环境下可稳定运行,支持多用户并发接入(接口层异步)与排队推理(任务层串行)。下一章将从工程实现角度给出启动脚本、前后端代码组织、模型加载流程与推理管线的具体落地方案,并补充实测性能数据验证设计目标的达成情况。
