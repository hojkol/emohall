\chapter{数字人视频生成系统实现}

本章承接第~\ref{sec:arch-design} 节的架构设计,给出系统的工程落地方案。实现层面包括启动脚本(\texttt{emohallo.sh})、前端应用(\texttt{emo\_hallo/Main.py})、后端服务(\texttt{emo\_hallo/backend/})、模型加载(\texttt{services/hallo2/})与推理管线(\texttt{hallo2\_pipeline.py})五个部分。

章节组织如下:第~\ref{sec:startup-script} 节展开启动脚本的进程管理与健康检查机制;第~\ref{sec:impl-frontend} 节给出前端的状态管理与 API 客户端实现;第~\ref{sec:impl-backend} 节阐述后端的接口实现、任务队列与模型加载流程;第~\ref{sec:performance-opt} 节分析性能优化策略;第~\ref{sec:testing} 节给出验证方法与实测数据。

\textbf{关键实测数据}: 模型加载耗时 12 分 47 秒,单任务推理耗时 9--23 分钟(取决于音频长度),基础显存占用 8--12GB,推理峰值额外需 4--6GB。

\section{启动脚本与服务编排}
\label{sec:startup-script}

\subsection{emohallo.sh 启动流程}

系统通过 \texttt{emohallo.sh} 统一拉起前后端服务,脚本实现聚焦"环境初始化、进程管理、健康检查、优雅关闭"四个环节。

\subsubsection{环境初始化}

脚本启动阶段完成以下环境配置:

\begin{enumerate}
    \item \textbf{代理清理}:
    \begin{verbatim}
export http_proxy="" https_proxy=""
export HTTP_PROXY="" HTTPS_PROXY=""
    \end{verbatim}
    清空代理变量,避免前端无法连接本地后端(\texttt{127.0.0.1:8001})。

    \item \textbf{GPU指定}:通过 \texttt{CUDA\_VISIBLE\_DEVICES} 指定 GPU 序号(默认 0)。

    \item \textbf{日志级别}:优先级为 \texttt{LOG\_LEVEL} 环境变量 > \texttt{EMO\_HALLO\_LOG\_LEVEL} > 默认 \texttt{INFO}。

    \item \textbf{Python环境}:从 \texttt{EMO\_HALLO\_ENV} 绑定 conda 环境路径(默认 \texttt{/remote-home/JJHe/.conda/envs/mpt})。
\end{enumerate}

\subsubsection{前端启动与 Watchdog Polling}

前端优先启动,以 Streamlit 运行 \texttt{emo\_hallo/Main.py}:

\begin{verbatim}
bash -c '
  export HOME=$(mktemp -d -p /tmp)  # 隔离配置目录
  export USE_POLLING_OBSERVER=true  # 规避inotify限制
  streamlit run ./emo_hallo/Main.py \
    --server.port=8501 \
    --logger.level=error \
    --client.toolbarMode=minimal > logs/frontend.log 2>&1
  rm -rf $HOME
' &
\end{verbatim}

\noindent \textbf{关键设计}:
\begin{itemize}
    \item \texttt{USE\_POLLING\_OBSERVER=true}:Streamlit 默认使用 \texttt{watchdog} 监听文件变化以触发热更新,在大型代码库中可能触发"inotify watch limit reached"错误;开启 polling 模式后改用轮询检测,规避系统限制。
    \item 临时 \texttt{HOME} 目录:避免 Streamlit 配置(\texttt{~/.streamlit/config.toml})污染用户环境。
\end{itemize}

\subsubsection{后端启动}

后端通过 Uvicorn 启动 FastAPI 应用:

\begin{verbatim}
PYTHONUNBUFFERED=1 stdbuf -oL -eL python -u -m uvicorn \
  emo_hallo.backend.app:app \
  --host "0.0.0.0" \
  --port 8001 \
  --log-level info >> logs/backend.log 2>&1 &
\end{verbatim}

\noindent \textbf{无缓冲输出}:\texttt{PYTHONUNBUFFERED=1} 与 \texttt{stdbuf -oL -eL} 确保日志实时写入,便于 \texttt{tail -f} 追踪模型加载进度。

\subsubsection{健康检查后台进程}

启动后台进程轮询 \texttt{/health} 端点,不阻塞前端启动:

\begin{verbatim}
(
  RETRY_COUNT=0
  while [ $RETRY_COUNT -lt 20 ]; do
    if curl -s http://127.0.0.1:8001/health > /dev/null 2>&1; then
      print_status "✓ Backend is ready!"
      break
    fi
    RETRY_COUNT=$((RETRY_COUNT + 1))
    sleep 60  # 每60秒检查一次
  done
) &
\end{verbatim}

\noindent \textbf{最大等待时间}:20 次 $\times$ 60 秒 = 20 分钟,覆盖模型加载耗时(实测约 12 分 47 秒)。

\subsubsection{优雅关闭与三层清理}

脚本捕获 \texttt{SIGINT/SIGTERM/EXIT} 信号后执行 \texttt{cleanup()} 函数,采用三层清理策略:

\begin{enumerate}
    \item \textbf{PID 直接 kill}:
    \begin{verbatim}
kill -9 $BACKEND_PID $FRONTEND_PID 2>/dev/null || true
    \end{verbatim}

    \item \textbf{命令模式匹配}:
    \begin{verbatim}
pkill -9 -f "emo_hallo.backend" 2>/dev/null || true
pkill -9 -f "emo_hallo/Main.py" 2>/dev/null || true
    \end{verbatim}

    \item \textbf{端口占用清理}:
    \begin{verbatim}
lsof -t -i :8001 | xargs kill -9 2>/dev/null || true
lsof -t -i :8501 | xargs kill -9 2>/dev/null || true
    \end{verbatim}
\end{enumerate}

\noindent \textbf{三层保险理由}:避免因 PID 失效、进程重命名或端口残留导致清理失败。

\section{前端实现}
\label{sec:impl-frontend}

该部分对应上一章“展示层”设计，重点落在组件组织、状态管理与 API 交互的实现细节。

\subsection{前端技术栈}

前端采用 Streamlit 构建交互界面与状态管理，配合轻量级 HTTP 客户端与日志体系完成“页面渲染 $\rightarrow$ 任务提交 $\rightarrow$ 状态回传”的闭环。核心技术栈如下：
\begin{itemize}
    \item \textbf{Streamlit}：负责界面构建、\texttt{Session State} 管理与定时刷新
    \item \textbf{requests}：对后端 REST API 进行请求封装
    \item \textbf{loguru}：输出前端运行日志与异常信息
\end{itemize}

\subsection{用户界面设计}

\subsubsection{主界面布局}

前端应用主界面采用竖向分栏布局，如图~\ref{fig:frontend_ui_layout}所示。界面按用户操作链路划分为四个区域（编号 1--4），覆盖输入上传、输入选择与任务触发、进度观测与结果展示，从而缩短操作路径并降低误操作概率。

\begin{figure}[htbp]
    \centering
    \begin{tikzpicture}[
        font=\small,
        box/.style={rectangle, draw, rounded corners, align=left, minimum width=0.9\linewidth, minimum height=1.1cm}
    ]
        \node[box] (upload) {1.\ \textbf{文件上传区}\quad 图像（JPG/PNG）与音频（WAV/MP3/OGG/M4A）上传，预览与格式校验};
        \node[box, below=0.35cm of upload] (params) {2.\ \textbf{输入选择区}\quad 选择当前图像/音频组合并触发生成};
        \node[box, below=0.35cm of params] (submit) {3.\ \textbf{任务进度区}\quad 进度条、状态与 ETA 实时反馈};
        \node[box, below=0.35cm of submit] (result) {4.\ \textbf{结果展示区}\quad Recent Creations 预览与下载};
    \end{tikzpicture}
    \caption{前端主界面布局示意（按交互链路划分）}
    \label{fig:frontend_ui_layout}
\end{figure}

\begin{enumerate}
    \item \textbf{文件上传区}
    \begin{itemize}
        \item 图像上传：支持 JPG/PNG 格式并提供预览
        \item 音频上传：支持 WAV/MP3/OGG/M4A 格式
        \item 文件校验：前端拦截异常后缀并提示
    \end{itemize}

    \item \textbf{输入选择区}
    \begin{itemize}
        \item 选择当前图像与音频组合
        \item 触发 \texttt{Generate} 按钮提交任务
    \end{itemize}

    \item \textbf{任务进度区}
    \begin{itemize}
        \item 进度条与状态文本
        \item ETA 估算与异常提示
    \end{itemize}

    \item \textbf{结果展示区}
    \begin{itemize}
        \item Recent Creations 列表
        \item 视频预览与下载
    \end{itemize}
\end{enumerate}

\subsection{前端核心功能}

\subsubsection{文件上传与去重}

前端通过 \texttt{st.file\_uploader()} 实现多文件上传，关键实现包括:

\paragraph{去重机制}

使用文件名集合避免重复上传:

\begin{verbatim}
existing_names = {f["name"] for f in st.session_state["uploaded_images"]}
for uploaded_file in uploader:
    if uploaded_file.name not in existing_names:
        file_id = str(uuid.uuid4())
        st.session_state["uploaded_images"][file_id] = {
            "name": uploaded_file.name,
            "data": uploaded_file.getvalue(),
            "type": uploaded_file.type
        }
\end{verbatim}

\paragraph{双层持久化策略}

\begin{enumerate}
    \item \textbf{Session State}(必选): 刷新页面后丢失，适合单次会话。
    \item \textbf{URL Query Params}(可选): 通过 \texttt{st.query\_params["task\_id"]} 持久化当前任务，刷新后可恢复进度查询；由 \texttt{EMO\_HALLO\_PERSIST\_UPLOADS} 环境变量控制，默认关闭以避免长 URL。
\end{enumerate}

\paragraph{临时文件处理}

任务提交时将内存中的文件写入 \texttt{tempfile.mkdtemp()}:

\begin{verbatim}
import tempfile
temp_dir = tempfile.mkdtemp()
image_path = os.path.join(temp_dir, image_name)
with open(image_path, "wb") as f:
    f.write(image_data)
\end{verbatim}

\noindent 避免阻塞主进程或污染项目目录。

\subsubsection{Fragment 机制的局部刷新}

Streamlit 默认每次交互触发全页重绘，导致性能开销大。\texttt{@st.fragment} 装饰器可实现局部刷新:

\begin{verbatim}
@st.fragment(run_every=2)  # 每2秒自动执行
def render_task_progress(task_id):
    status = backend_client.get_task_status(task_id)
    st.progress(status["progress"] / 100)  # 只更新进度条
    st.text(status["status_message"])      # 只更新状态文本
\end{verbatim}

\noindent \textbf{Fragment vs 全页刷新对比}:

\begin{table}[h]
    \centering
    \caption{Fragment 局部刷新的性能优势}
    \small
    \begin{tabular}{l|c|c}
        \hline
        指标 & 全页刷新 & Fragment局部刷新 \\
        \hline
        重新执行范围 & 整个脚本 & 仅Fragment函数内 \\
        Session State 重置 & 可能丢失 & 保持不变 \\
        刷新延迟 & 200--500 ms & 50--100 ms \\
        CPU占用 & 高 & 低 \\
        \hline
    \end{tabular}
\end{table}

\paragraph{进度归一化}

后端可能返回 0--1 或 0--100 两种进度格式，前端统一归一化:

\begin{verbatim}
progress = status.get("progress", 0)
if 0 <= progress <= 1:
    progress *= 100  # 转为百分比
st.progress(int(progress))
\end{verbatim}

\paragraph{ETA 计算}

后端 StateManager 根据已用时间与进度比例估算剩余时间:

\begin{verbatim}
# 后端计算逻辑
elapsed = time.time() - task["started_at"]
eta = (elapsed / progress) * (100 - progress)
\end{verbatim}

前端显示为人类可读格式:"约 5 分钟剩余"。

\paragraph{错误处理与任务保持}

任务失败时保留 \texttt{task\_id},允许用户重新查看错误日志:

\begin{verbatim}
if status["status"] == "failed":
    st.error(f"任务失败: {status['error']}")
    # 不清除 task_id,保留上下文
\end{verbatim}

\begin{figure}[htbp]
    \centering
    \begin{tikzpicture}[
        font=\small,
        node distance=1.35cm and 1.8cm,
        actor/.style={rectangle, draw, rounded corners, align=center, minimum width=2.6cm, minimum height=0.9cm},
        arrow/.style={->, thick}
    ]
        \node[actor] (user) {用户};
        \node[actor, right=of user] (st) {Streamlit\\前端应用};
        \node[actor, right=of st] (api) {FastAPI\\后端 API};

        \draw[arrow] (user) -- node[above, align=center]{\shortstack{上传图像/音频\\选择输入}} (st);
        \draw[arrow] (st) -- node[above]{POST \ \texttt{/api/v1/inference/hallo2}} (api);
        \draw[arrow] (api) -- node[below]{返回 \texttt{task\_id}} (st);
        \draw[arrow] (st) -- node[above]{轮询 GET \ \texttt{/api/v1/tasks/\{task\_id\}}} (api);
        \draw[arrow] (api) -- node[below]{返回状态/进度/错误} (st);
        \draw[arrow] (st) -- node[above, align=center]{\shortstack{下载结果\\GET \ \texttt{/api/v1/tasks/\{task\_id\}/video}}} (api);
        \draw[arrow] (api) -- node[below]{返回 MP4} (st);
        \draw[arrow] (st) -- node[above]{预览/下载} (user);
    \end{tikzpicture}
    \caption{前端--后端交互的任务流程示意}
    \label{fig:frontend_task_sequence}
\end{figure}

\subsubsection{API 客户端实现}

前端通过 \texttt{HalloBackendClient} 类封装 HTTP 调用，代码位于 \texttt{emo\_hallo/Main.py} 中。

\paragraph{客户端初始化}

\begin{verbatim}
class HalloBackendClient:
    def __init__(self, base_url: str, timeout: int = 30):
        self.base_url = base_url  # 从 BACKEND_URL 环境变量读取
        self.timeout = timeout
        self.session = requests.Session()  # 复用连接
\end{verbatim}

\paragraph{健康检查与缓存}

健康检查接口带 5 秒缓存，避免频繁请求:

\begin{verbatim}
@st.cache_data(ttl=5)  # 5秒缓存
def health_check(self) -> dict:
    try:
        resp = self.session.get(
            f"{self.base_url}/health",
            timeout=3
        )
        return {"status": "healthy", "gpu": resp.json()["gpu"]}
    except requests.RequestException:
        return {"status": "unhealthy"}
\end{verbatim}

\paragraph{任务提交}

使用 \texttt{multipart/form-data} 上传文件:

\begin{verbatim}
def create_inference(self, image_path: str, audio_path: str,
                     use_cache: bool = True) -> dict:
    files = {
        "image": open(image_path, "rb"),
        "audio": open(audio_path, "rb")
    }
    data = {"use_cache": str(use_cache).lower()}

    resp = self.session.post(
        f"{self.base_url}/api/v1/inference/hallo2",
        files=files,
        data=data,
        timeout=self.timeout
    )
    return resp.json()  # {"task_id": "...", "status": "pending"}
\end{verbatim}

\paragraph{Recent Videos 缓存策略}

最近作品列表带 15 秒 TTL，减少后端压力:

\begin{verbatim}
@st.cache_data(ttl=15)  # 15秒缓存
def get_recent_videos(self, limit: int = 10) -> list:
    resp = self.session.get(
        f"{self.base_url}/api/v1/tasks/recent",
        params={"limit": limit}
    )
    return resp.json()["tasks"]
\end{verbatim}

\noindent \textbf{缓存窗口设计理由}:
\begin{itemize}
    \item 健康检查 5 秒: 快速反馈后端状态，不频繁查询
    \item Recent videos 15 秒: 用户浏览历史时短期内无需重新拉取
    \item 任务状态不缓存: 必须实时查询以更新进度条
\end{itemize}

\subsection{国际化支持}

系统支持多语言界面切换，采用键值映射的文案检索机制实现：

\begin{itemize}
    \item 顶部选择器提供多语言选项（如 zh-CN、en-US 等）
    \item 当前语言写入 \texttt{st.session\_state["ui\_language"]} 并同步至配置
    \item \texttt{tr(key)} 根据键值返回本地化文本
    \item 语言切换触发页面重渲染，使文案即时生效
\end{itemize}

在实现层面，语言状态与 UI 文案解耦，界面层只感知 \texttt{tr()} 的返回值，便于后续扩展术语表与多语种资源。

本章前端部分给出了交互界面、任务提交与进度反馈机制的实现要点。下一节将进一步介绍后端推理模块与任务管理逻辑的实现，以展示系统整体的工程化落地能力与可扩展性设计。

\section{后端实现}
\label{sec:impl-backend}

本节在上一章系统设计的基础上，重点从工程实现角度阐述后端的接口组织、任务异步调度、模型管理与推理管线落地方法。为提升可读性，后端实现按“接口层 $\rightarrow$ 调度层 $\rightarrow$ 模型与推理”逐级展开。

\subsection{API实现}

\subsubsection{API路由设计}

后端采用 RESTful 风格设计 API，原则层面的约束已在上一章给出，本节强调实现层的落地方式：

\begin{itemize}
    \item 资源导向：URI表示资源而非操作
    \item HTTP 动词：使用 GET、POST、DELETE 等标准 HTTP 方法
    \item 版本控制：使用\texttt{/api/v1/}路径前缀
    \item 结构化响应：状态、进度与错误信息以 JSON 返回
\end{itemize}

核心API端点的实现详见表~\ref{tab:api_endpoints}。

工程实现上，路由在 FastAPI 生命周期启动阶段统一注册，确保健康检查与任务接口在模型加载期间即可响应，从而降低冷启动阶段的交互阻塞。

\subsubsection{数据验证和序列化}

系统使用 Pydantic 对响应结构进行类型约束，并在接口入口完成必要的参数校验，降低无效请求进入推理链路的概率。核心数据模型包括：

\begin{enumerate}
    \item \textbf{响应数据模型}
    \begin{itemize}
        \item \texttt{Hallo2InferenceResponse}：推理提交响应（包含 task\_id）
        \item \texttt{TaskStatusResponse}：任务状态响应（进度、状态、ETA、结果）
        \item \texttt{ModelsListResponse} / \texttt{ModelInfoResponse}：模型状态与元信息
        \item \texttt{HealthResponse}：健康检查响应
        \item \texttt{ErrorResponse}：错误响应结构
    \end{itemize}
\end{enumerate}

推理任务提交采用 \texttt{UploadFile} + \texttt{Form} 参数（\texttt{use\_cache}），并在后端进行文件扩展名白名单校验，非法输入直接返回 4xx；该策略将异常拦截在接口入口，避免进入 GPU 推理阶段。

\subsubsection{服务生命周期与日志}

后端在 \texttt{lifespan} 生命周期内完成路由注册、模型初始化与任务调度器装配。服务启动阶段加载配置并注册 \texttt{hallo2} 模型，同时预加载全局模型实例；服务关闭阶段调用 TaskManager 收敛队列并卸载模型，释放显存。日志系统由 \texttt{setup\_logging()} 初始化，输出路径固定为 \texttt{logs/backend.log}，并通过 \texttt{LOG\_LEVEL} 控制日志等级。

\subsection{任务管理系统}

\subsubsection{任务队列与 RLock 机制}

系统采用 \texttt{queue.Queue} + \texttt{threading.RLock} 实现线程安全的任务调度。

\paragraph{queue.Queue vs asyncio.Queue}

选择标准库 \texttt{queue.Queue} 的理由:

\begin{table}[h]
    \centering
    \caption{任务队列方案对比}
    \small
    \begin{tabular}{l|l|l}
        \hline
        方案 & 优势 & 劣势 \\
        \hline
        \textbf{queue.Queue} &
        \begin{tabular}[t]{@{}l@{}}线程安全\\阻塞式消费,逻辑简单\\无外部依赖\end{tabular} &
        单进程内有效 \\
        \hline
        asyncio.Queue &
        协程原生支持 &
        \begin{tabular}[t]{@{}l@{}}与线程模型不兼容\\推理库多为同步调用\end{tabular} \\
        \hline
    \end{tabular}
\end{table}

\noindent Hallo2Pipeline、InsightFace、Wav2Vec2 等推理库为同步调用，使用 \texttt{asyncio.Queue} 需额外用 \texttt{run\_in\_executor()} 包装，增加复杂度。

\paragraph{RLock 可重入锁}

使用 \texttt{threading.RLock} 而非 \texttt{Lock}:

\begin{verbatim}
class TaskManager:
    def __init__(self):
        self.lock = threading.RLock()  # 可重入锁
        self.current_tasks = 0
        self.max_concurrent = 1
\end{verbatim}

\noindent \textbf{RLock 应用场景}:

\begin{verbatim}
def submit_task(self, task):
    with self.lock:  # 获取锁
        self.queue.put(task)
        self._try_start_worker()  # 内部再次获取锁(重入)

def _try_start_worker(self):
    with self.lock:  # 重入,不会死锁
        if self.current_tasks < self.max_concurrent:
            threading.Thread(target=self._worker).start()
\end{verbatim}

\noindent 若使用普通 \texttt{Lock}，\texttt{\_try\_start\_worker()} 内再次 \texttt{with self.lock} 会死锁；\texttt{RLock} 允许同一线程多次获取。

\subsubsection{并发控制机制}

为防止 GPU 显存溢出（OOM）并维持系统计算稳定性，后端引入并发控制机制，对推理任务的并发上限进行约束：

\begin{itemize}
    \item 通过锁与 \texttt{current\_tasks} 计数限制并发
    \item 默认最多同时运行 1 个推理任务（由配置项 \texttt{max\_concurrent\_tasks} 控制）
    \item 超过限制的任务进入等待队列
    \item 任务完成后自动分配给下一个等待的任务
\end{itemize}

该机制通过“并发上限 $\rightarrow$ 资源占用可控”的方式，将显存不确定性转化为可治理的排队等待，从而在单 GPU 环境下提升系统稳定性与可预测性。

\subsubsection{任务生命周期}

任务的完整生命周期包括以下阶段：

\begin{enumerate}
    \item \textbf{创建（Creation）}：API 端点接收请求，创建新任务
    \begin{itemize}
        \item 生成唯一的 \texttt{task\_id}
        \item 验证输入参数
        \item 保存上传文件到 \texttt{logs/uploads/\{task\_id\}/} 目录
        \item 初始化任务状态为 \texttt{pending}
    \end{itemize}

    \item \textbf{等待（Waiting）}：任务进入队列等待执行
    \begin{itemize}
        \item 如果并发限制未满足，立即分配给消费者线程
        \item 否则进入等待队列
    \end{itemize}

    \item \textbf{运行（Processing）}：后台线程执行推理任务
    \begin{itemize}
        \item 启动 \texttt{Hallo2Pipeline} 进行推理
        \item 实时更新任务进度（0--100\%）
        \item 任务状态写入内存状态表，并更新 ETA
    \end{itemize}

    \item \textbf{完成（Completion）}：任务执行成功或失败
    \begin{itemize}
        \item 成功：更新状态为 \texttt{completed}，保存生成的视频
        \item 失败：更新状态为 \texttt{failed}，保存错误信息
    \end{itemize}

    \item \textbf{收敛（Finish）}：释放任务执行槽位并触发队列调度
\end{enumerate}

\subsubsection{任务取消的边界}

系统支持取消 \texttt{pending} 状态任务，但 \texttt{processing} 任务不可强制中断:

\begin{verbatim}
def cancel_task(self, task_id):
    with self.lock:
        task = self.state_manager.get_task(task_id)
        if task["status"] == "pending":
            # 从队列中移除(需遍历Queue,重新入队非目标任务)
            self.state_manager.fail_task(task_id, "Cancelled by user")
            return True
        elif task["status"] == "processing":
            return False  # 不支持中断running任务
\end{verbatim}

\noindent \textbf{不支持中断running任务的原因}:
\begin{enumerate}
    \item \textbf{GPU操作不可回滚}: 扩散模型已完成的去噪步数无法撤销，强制中断导致显存泄漏。
    \item \textbf{中间状态难以清理}: 临时文件(mask、audio\_emb)已写入磁盘，需额外回收逻辑。
    \item \textbf{复杂度收益比低}: 推理通常9--23分钟完成，用户可等待或重启服务。
\end{enumerate}

\subsubsection{错误处理体系}

系统定义分层异常类，便于上层代码精确捕获:

\begin{verbatim}
# emo_hallo/backend/utils/error_handler.py
class Hallo2Exception(Exception):
    """基类"""
    pass

class ValidationError(Hallo2Exception):
    """输入验证失败"""
    pass

class ModelLoadError(Hallo2Exception):
    """模型加载失败"""
    pass

class InferenceError(Hallo2Exception):
    """推理执行失败"""
    pass

class GPUError(Hallo2Exception):
    """GPU相关错误(OOM等)"""
    pass
\end{verbatim}

\noindent \textbf{装饰器自动捕获}:

\begin{verbatim}
@handle_exceptions  # 自动捕获并转换为HTTP响应
def inference_endpoint():
    # 业务逻辑
\end{verbatim}

\subsection{模型与推理实现}

\subsubsection{模型加载的 8 阶段流程}

Hallo2 模型由 8 个子模块组成，后端在 \texttt{lifespan} 启动阶段依次加载。代码位于 \texttt{emo\_hallo/backend/services/hallo2/hallo2\_model.py}。

\paragraph{加载顺序与依赖}

\begin{table}[h]
    \centering
    \caption{Hallo2 模型加载 8 阶段}
    \small
    \begin{tabular}{c|l|l|l}
        \hline
        阶段 & 模块名称 & 功能 & 典型耗时 \\
        \hline
        1/8 & VAE (AutoencoderKL) & 图像/视频潜空间编解码 & 30--60 s \\
        2/8 & Reference UNet2D & 参考图像身份编码 & 60--90 s \\
        3/8 & Denoising UNet3D + Motion Module & 时序去噪与运动建模 & 180--300 s \\
        4/8 & FaceLocator & 人脸区域定位 & 30--45 s \\
        5/8 & ImageProj + AudioProj & 条件投影模块 & 45--60 s \\
        6/8 & Net (联合checkpoint) & 加载联合权重 & 120--180 s \\
        7/8 & DDIM Scheduler & 调度器配置 & 5--10 s \\
        8/8 & MaskPredictUNet (可选) & 面部/唇部掩码预测 & 60--90 s \\
        \hline
        \multicolumn{3}{r|}{\textbf{总耗时(实测)}} & \textbf{12 分 47 秒} \\
        \hline
    \end{tabular}
\end{table}

\paragraph{日志样例}

\begin{verbatim}
10:20:36 INFO [1/8] Loading VAE from /path/to/vae/...
10:21:06 INFO [2/8] Loading Reference UNet2D...
10:22:14 INFO [3/8] Loading Denoising UNet3D + Motion Module...
10:27:35 INFO [4/8] Loading FaceLocator...
10:28:12 INFO [5/8] Loading Projectors (Image + Audio)...
10:29:18 INFO [6/8] Loading Net from joint checkpoint...
10:32:05 INFO [7/8] Configuring DDIM Scheduler...
10:32:10 INFO [8/8] Loading MaskPredictUNet (optional)...
10:33:23 INFO ✓ Hallo2 model loaded successfully (Total: 12m47s)
\end{verbatim}

\paragraph{关键设计点}

\begin{enumerate}
    \item \textbf{顺序约束}: Net (阶段6) 必须在 UNet2D/3D 加载后执行，因其加载联合 checkpoint 需覆盖前序权重。
    \item \textbf{可选组件}: MaskPredictUNet 可通过配置禁用，节省 60--90 秒加载时间与 ~2GB 显存。
    \item \textbf{日志可观测}: 每阶段打印 \texttt{[N/8]} 前缀，用户可通过 \texttt{tail -f logs/backend.log} 追踪进度。
    \item \textbf{失败回滚}: 任一阶段加载失败抛出 \texttt{ModelLoadError}，服务启动失败但不崩溃。
\end{enumerate}

\paragraph{ModelRegistry 缓存机制}

\begin{verbatim}
class ModelRegistry:
    _instances = {}  # 全局实例缓存

    @classmethod
    def get_model(cls, name: str):
        if name not in cls._instances:
            cls._instances[name] = cls._load_model(name)
        return cls._instances[name]  # 复用已加载实例
\end{verbatim}

\noindent 后续推理任务直接调用 \texttt{get\_model("hallo2")}，返回缓存实例，避免重复加载 12 分钟。

\subsubsection{延迟加载机制}

为降低启动开销并节省显存/内存占用，系统在模型注册层引入延迟加载机制，同时在推理路径采取“预加载 + 常驻”策略：

\begin{itemize}
    \item ModelRegistry 在首次访问时加载模型实例并缓存
    \item 后端生命周期启动阶段预加载全局 Hallo2 模型实例，避免首个任务冷启动
    \item 任务执行阶段复用全局模型实例，避免重复加载
\end{itemize}

其核心逻辑可抽象为如下伪代码：
\begin{verbatim}
if model_name not in cache:
    model = load_model_from_disk(model_name)
    cache[model_name] = model
return cache[model_name]
\end{verbatim}

\subsubsection{缓存和生命周期管理}

系统使用实例缓存与生命周期回收机制管理模型实例：

\begin{itemize}
    \item \textbf{实例缓存}：\texttt{ModelRegistry.\_instances} 维护已加载实例
    \item \textbf{卸载接口}：提供 \texttt{unload\_model()} 与 \texttt{unload\_all\_models()} 回收显存
    \item \textbf{生命周期回收}：服务退出时主动卸载全局模型并清理缓存
\end{itemize}

\subsubsection{Hallo2 推理管道与自回归生成}

\paragraph{推理管道概述}

Hallo2 推理管道采用三阶段架构（预处理 $\rightarrow$ 推理 $\rightarrow$ 后处理），代码位于 \texttt{emo\_hallo/backend/services/hallo2/hallo2\_pipeline.py} (555行)。该抽象有助于在实现中对不同阶段进行解耦优化，并为性能评测与故障定位提供明确边界。

\begin{figure}[h]
    \centering
    \begin{tikzpicture}[
        font=\small,
        box/.style={rectangle, draw, rounded corners, align=center, minimum width=2.8cm, minimum height=0.9cm},
        arrow/.style={->, thick},
        node distance=1.25cm and 1.35cm
    ]
        \node[box] (img) {图像输入\\JPG/PNG};
        \node[box, below=of img] (aud) {音频输入\\WAV/MP3};

        \node[box, right=of img] (imgpre) {图像预处理\\检测/对齐/掩码};
        \node[box, right=of aud] (audpre) {音频预处理\\特征提取/对齐};

        \node[box, right=1.8cm of imgpre] (cond) {条件构建\\身份特征+音频特征};
        \node[box, right=of cond] (diff) {扩散去噪生成\\UNet3D};
        \node[box, right=of diff] (vae) {VAE 解码\\得到帧序列};

        \node[box, below=of vae] (post) {后处理\\编码/合成};
        \node[box, right=of post] (out) {输出视频\\MP4};

        \draw[arrow] (img) -- (imgpre);
        \draw[arrow] (aud) -- (audpre);
        \draw[arrow] (imgpre) -- (cond);
        \draw[arrow] (audpre) -- (cond);
        \draw[arrow] (cond) -- (diff);
        \draw[arrow] (diff) -- (vae);
        \draw[arrow] (vae) -- (post);
        \draw[arrow] (post) -- (out);
    \end{tikzpicture}
    \caption{Hallo2 推理管道的三阶段数据流示意}
    \label{fig:inference_pipeline}
\end{figure}

\paragraph{预处理阶段}

预处理阶段对输入的图像和音频进行处理，为推理做准备。

\subparagraph{图像预处理}

\begin{enumerate}
    \item \textbf{人脸检测}
    \begin{itemize}
        \item 基于 InsightFace 的 \texttt{FaceAnalysis} 检测人脸框
        \item 多人脸场景下选择面积最大的目标
        \item 未检测到人脸时退化为整图区域
    \end{itemize}

    \item \textbf{掩码生成}
    \begin{itemize}
        \item 调用 \texttt{get\_mask()} 生成 face/lip/background 掩码
        \item 掩码文件缓存在任务目录，命中缓存时直接复用
        \item 生成多尺度掩码用于后续注意力与区域约束
    \end{itemize}

    \item \textbf{特征提取}
    \begin{itemize}
        \item 提取人脸 embedding 作为身份条件
        \item 图像张量统一尺寸并进行归一化
        \item 生成多尺度掩码展开用于推理阶段
    \end{itemize}
\end{enumerate}

\subparagraph{音频预处理}

\begin{enumerate}
    \item \textbf{音频分离}
    \begin{itemize}
        \item 可选的 \texttt{audio\_separator} 模型进行人声分离
        \item 未配置分离模型时直接使用原音频
    \end{itemize}

    \item \textbf{特征提取}
    \begin{itemize}
        \item 将音频重采样至 16 kHz
        \item 使用 Wav2Vec2 提取音频嵌入
        \item 按 FPS 计算序列长度并进行时间对齐
    \end{itemize}

    \item \textbf{同步对齐}
    \begin{itemize}
        \item 长音频可分段切片并拼接嵌入序列
        \item 按 \texttt{n\_sample\_frames} 对齐片段长度与 padding
    \end{itemize}
\end{enumerate}

\paragraph{推理阶段：自回归Clip生成}

推理阶段采用 \textbf{Clip-based 自回归生成}，每次生成 16 帧 (\texttt{n\_sample\_frames=16})，逐 clip 拼接为完整视频。

\subparagraph{自回归生成伪代码}

\begin{verbatim}
def generate_video(audio_emb, face_emb, total_frames):
    clips = []
    motion_frames = None  # 首clip无运动参考

    for clip_idx in range(0, total_frames, 16):
        # 1. 准备motion frames
        if motion_frames is None:
            motion_frames = torch.zeros((2, 3, H, W))  # 零初始化
        else:
            motion_frames = clips[-1][-2:]  # 取前一clip末尾2帧

        # 2. 提取当前clip的音频片段
        audio_clip = audio_emb[clip_idx:clip_idx+16]

        # 3. 扩散去噪生成16帧
        latents = diffusion_model(
            audio=audio_clip,
            face_emb=face_emb,
            motion_frames=motion_frames,  # 作为初始条件
            num_steps=40
        )

        # 4. VAE解码为像素空间
        frames = vae.decode(latents)  # [16, 3, H, W]

        # 5. 帧连续性修复：用前一clip实际末帧替换当前clip首帧
        if len(clips) > 0:
            frames[0] = clips[-1][-1]  # 替换为前一clip的最后一帧

        clips.append(frames)

    return torch.cat(clips, dim=0)  # 拼接所有clips
\end{verbatim}

\subparagraph{帧连续性修复}

自回归生成存在clip边界不连续问题。代码采用 \textbf{实际末帧替换策略}:

\begin{itemize}
    \item \textbf{问题}: motion\_frames 仅作为扩散初始条件，生成的首帧与前一clip末帧仍可能不连续。
    \item \textbf{解决}: 用前一clip的实际末帧 \texttt{clips[-1][-1]} 直接替换当前clip首帧 \texttt{frames[0]}。
    \item \textbf{代价}: 牺牲1帧的生成多样性，换取视觉连续性。
\end{itemize}

\subparagraph{Wav2Vec2 多层特征}

音频特征提取器输出 12 层 hidden states:

\begin{verbatim}
# emo_hallo/backend/services/hallo2/processors/wav2vec.py
outputs = model(audio, output_hidden_states=True)
audio_emb = torch.stack(outputs.hidden_states, dim=1)  # [T, 12, 768]
\end{verbatim}

\noindent AudioProj 模块融合 12 层特征为单一表示，用于驱动 Motion Module。

\subparagraph{模型组件}

Hallo2 推理使用以下核心模型组件：

\begin{enumerate}
    \item \textbf{VAE（Variational Autoencoder, 变分自编码器）}
    \begin{itemize}
        \item 编码：将高分辨率图像编码为低维潜在空间
        \item 解码：将生成的潜在向量解码为视频帧
    \end{itemize}

    \item \textbf{Reference UNet2D}
    \begin{itemize}
        \item 以参考图像为条件
        \item 提取参考人物的样式和身份信息
        \item 确保生成视频中的人物与参考图像相同
    \end{itemize}

    \item \textbf{Denoising UNet3D}
    \begin{itemize}
        \item 3D卷积架构，用于时间维度的连贯性
        \item 通过逐步去噪生成视频序列
        \item 接收音频特征作为运动控制信号
    \end{itemize}

    \item \textbf{FaceLocator}
    \begin{itemize}
        \item 进行人脸定位和空间对齐
        \item 确保生成的人脸位置与参考图像对齐
        \item 处理人脸变形和变换
    \end{itemize}

    \item \textbf{ImageProj / AudioProj}
    \begin{itemize}
        \item 将图像与音频条件映射到统一特征空间
        \item 为 UNet3D 提供跨模态条件输入
    \end{itemize}

    \item \textbf{MaskPredictUNet}
    \begin{itemize}
        \item 预测 face/lip 掩码序列
        \item 强化口型区域约束，抑制非目标区域扰动
    \end{itemize}
\end{enumerate}

为便于读者从“输入--输出”的角度理解各模块职责，表~\ref{tab:hallo2_components}总结了主要组件的输入输出与功能定位。

\begin{table}[htbp]
    \centering
    \caption{Hallo2 推理管道关键组件的输入输出与功能说明}
    \label{tab:hallo2_components}
    \small
    \setlength{\tabcolsep}{4pt}
    \renewcommand{\arraystretch}{1.05}
    \begin{tabular}{l p{3.2cm} p{3.2cm} p{4.2cm}}
        \hline
        组件 & 输入 & 输出 & 功能 \\
        \hline
        Reference UNet2D & 参考图像 & 身份/外观特征 & 提取身份与外观条件 \\
        Denoising UNet3D & 噪声、条件特征（含音频） & 视频潜变量序列 & 多帧去噪生成与时序建模 \\
        Motion Module & 音频特征 & 运动驱动信号 & 语音节奏映射为表情/口型驱动 \\
        ImageProj/AudioProj & 图像/音频特征 & 条件嵌入 & 跨模态条件投影 \\
        MaskPredictUNet & 掩码序列与音频特征 & face/lip 掩码 & 口型区域约束与平滑 \\
        FaceLocator & 生成帧/特征 & 空间对齐参数 & 人脸区域定位与对齐校正 \\
        VAE & 潜变量/帧特征 & 像素空间帧序列 & 潜空间与像素空间编解码 \\
        \hline
    \end{tabular}
\end{table}

\subparagraph{推理过程}

\begin{enumerate}
    \item \textbf{条件编码}
    \begin{itemize}
        \item 参考图像编码为身份条件，音频嵌入映射为运动条件
        \item 条件投影后进入 UNet3D 的跨模态注意力路径
    \end{itemize}

    \item \textbf{分片生成}
    \begin{itemize}
        \item 按 \texttt{n\_sample\_frames} 切片生成
        \item 每个片段完成后追加到视频序列
        \item 通过回调更新进度与状态
    \end{itemize}

    \item \textbf{掩码引导}
    \begin{itemize}
        \item MaskPredictUNet 生成 face/lip 掩码
        \item 使用掩码约束面部区域，提升时序稳定性
    \end{itemize}
\end{enumerate}

\subparagraph{GPU优化}

为降低显存峰值并稳定推理链路，系统采用以下工程策略：

\begin{itemize}
    \item \textbf{精度选择}：GPU 可用时默认 \texttt{float16}，CPU 回退为 \texttt{float32}
    \item \textbf{模型常驻}：全局模型实例在启动阶段预加载并复用
    \item \textbf{并发约束}：默认单任务串行以抑制显存争用
\end{itemize}

上述策略将推理链路的峰值显存与启动抖动收敛到可控区间，后续可通过显存峰值与耗时指标进行量化对比。

\paragraph{后处理阶段}

后处理阶段对生成的视频进行最终处理。

\subparagraph{视频合成}

\begin{itemize}
    \item \textbf{帧序列整合}：将生成帧序列拼接为连续视频
    \item \textbf{视频编码}：通过 PyAV/FFmpeg 输出 MP4
\end{itemize}

\subparagraph{音频混合}

\begin{itemize}
    \item \textbf{音频合流}：任务目录存在音频时合并到输出视频
    \item \textbf{降级路径}：未检测到音频时输出纯视频
\end{itemize}

\subparagraph{输出处理}

\begin{itemize}
    \item \textbf{文件保存}：输出写入 \texttt{logs/uploads/\{task\_id\}/output.mp4}
    \item \textbf{结果回写}：将 \texttt{video\_path} 写入任务结果字段供下载接口查询
\end{itemize}

综上，模型与推理实现通过“插件化模型管理 + 分阶段推理管线”的方式，在保证扩展性的同时维持了推理流程的可解释性与可调优空间。

本节系统性介绍了后端的 API 组织、任务调度与模型推理落地方法。通过将推理任务异步化并引入并发治理，系统能够在资源受限的单机环境下保持稳定运行；同时，插件化的模型管理与分阶段推理管线为后续模型替换与性能优化提供了工程支点。下一节将进一步从性能与安全两个维度给出优化策略与设计约束。

\section{系统性能与安全设计}

\subsection{性能优化策略}

\subsubsection{模型加载与内存优化}

\begin{enumerate}
    \item \textbf{启动预加载}
    \begin{itemize}
        \item FastAPI 生命周期启动阶段加载全局 Hallo2 模型实例
        \item 冷启动耗时前置到服务启动期，避免首个任务阻塞
        \item 日志样例显示单次预加载约 12 分 47 秒（\texttt{10:20:36} $\rightarrow$ \texttt{10:33:23}）
    \end{itemize}

    \item \textbf{实例复用}
    \begin{itemize}
        \item 推理路径复用全局模型实例，避免重复权重加载
        \item ModelRegistry 使用实例缓存保存已加载模型
    \end{itemize}

    \item \textbf{回收策略}
    \begin{itemize}
        \item 服务退出时卸载全局模型并释放显存
        \item 按需调用 \texttt{torch.cuda.empty\_cache()} 回收缓存
    \end{itemize}
\end{enumerate}

\subsubsection{推理性能与 GPU 优化}

\begin{enumerate}
    \item \textbf{精度策略}
    \begin{itemize}
        \item GPU 可用时默认 \texttt{float16}，CPU 回退为 \texttt{float32}
        \item 精度与显存占用间进行工程权衡
    \end{itemize}

    \item \textbf{片段推理}
    \begin{itemize}
        \item 按 \texttt{n\_sample\_frames} 分片生成，降低单次显存峰值
        \item 片段拼接降低长音频推理的内存抖动
    \end{itemize}

    \item \textbf{显存回收}
    \begin{itemize}
        \item 卸载模型时触发 \texttt{torch.cuda.empty\_cache()}
    \end{itemize}
\end{enumerate}

\noindent 上述机制的设计目标是在生成质量、推理速度与显存占用之间实现可控权衡；其量化效果可在后续性能评估章节通过显存峰值、平均生成耗时等指标进一步验证。

\subsubsection{并发与任务调度}

\begin{enumerate}
    \item \textbf{异步处理}
    \begin{itemize}
        \item FastAPI 构建于 ASGI（Asynchronous Server Gateway Interface）之上，API 请求可异步调度，从而避免 I/O 阻塞并提升并发接入能力
        \item 前端 HTTP 请求与后端推理任务解耦，接口层快速返回 \texttt{task\_id} 并由后台执行推理
        \item 多个请求可并发处理
    \end{itemize}

    \item \textbf{后台线程执行}
    \begin{itemize}
        \item 推理任务在守护线程执行
        \item API 线程保持轻量响应
    \end{itemize}

    \item \textbf{任务队列调度}
    \begin{itemize}
        \item 任务按 FIFO 顺序出队
        \item 队列空闲后立即调度下一任务
    \end{itemize}
\end{enumerate}

\noindent 通过异步化与队列调度机制，系统将推理计算的资源争用问题转化为可治理的排队等待，从而在高并发接入场景下提升整体吞吐并保持运行稳定性。

\subsection{系统安全设计}

\subsubsection{输入与文件安全}

\begin{enumerate}
    \item \textbf{文件后缀白名单}
    \begin{itemize}
        \item 后端对图像与音频扩展名进行白名单校验
        \item 非法后缀直接返回 4xx
    \end{itemize}

    \item \textbf{上传尺寸约束}
    \begin{itemize}
        \item Streamlit 侧设置 \texttt{STREAMLIT\_SERVER\_MAX\_UPLOAD\_SIZE}（默认 500 MB）
        \item 通过前端限制避免超大文件占用
    \end{itemize}

    \item \textbf{路径隔离}
    \begin{itemize}
        \item 上传文件存储在 \texttt{logs/uploads/\{task\_id\}/} 目录
        \item 任务目录独立，避免互相覆盖
    \end{itemize}
\end{enumerate}

\noindent 综上，输入与文件安全策略通过“入口校验 + 路径隔离 + 内容识别”的组合方式降低了无效输入与潜在攻击面对系统稳定性的影响。

\subsubsection{异常与日志安全}

\begin{enumerate}
    \item \textbf{全局异常处理}
    \begin{itemize}
        \item 接口层通过 try-except 捕获异常并返回错误信息
        \item 防止异常扩散导致进程崩溃
    \end{itemize}

    \item \textbf{日志策略}
    \begin{itemize}
        \item 后端日志写入 \texttt{logs/backend.log}，前端日志写入 \texttt{logs/frontend.log}
        \item 日志级别由 \texttt{LOG\_LEVEL} 环境变量控制
    \end{itemize}

    \item \textbf{审计日志}
    \begin{itemize}
        \item 记录任务创建、执行与异常信息
        \item 支持回溯任务执行过程
    \end{itemize}
\end{enumerate}

\noindent 通过统一异常处理与日志分级策略，系统在保证可观测性的同时降低敏感信息泄露风险，为长期运行与问题追溯提供支撑。

\subsubsection{资源访问控制}

\begin{enumerate}
    \item \textbf{并发限制}
    \begin{itemize}
        \item 限制同时执行的推理任务数
        \item 防止 GPU 显存溢出
        \item 保证系统稳定性
    \end{itemize}

    \item \textbf{任务取消}
    \begin{itemize}
        \item 支持取消队列中未执行的任务
        \item 运行中任务不强制中断
    \end{itemize}

    \item \textbf{上传限制}
    \begin{itemize}
        \item 通过 Streamlit 最大上传尺寸限制输入大小
        \item 缓解磁盘占用压力
    \end{itemize}
\end{enumerate}

\noindent 本章从性能与安全两方面对系统进行了工程约束。通过模型预加载、\texttt{float16} 精度策略与队列调度，推理链路在单 GPU 环境下保持可控；同时借助后缀白名单、任务目录隔离与日志审计降低输入风险。上述机制的实际效果将在后续实验与评估章节中结合性能对比与异常场景测试进行验证。

\section{系统测试与评估}

\subsection{测试体系}

\noindent 本节介绍当前系统的验证路径，重点覆盖脚本化诊断、端到端调用与人工回归，以保证部署可用性与问题可追踪性。

\subsubsection{单元测试}

当前仓库中的单元测试主要覆盖 \texttt{app/services} 目录下的通用功能模块，采用 \texttt{unittest} 组织测试用例；针对 emo\_hallo 的推理链路，更多采用脚本化验证与人工回归。该安排减少了对 GPU 环境的强依赖，保证在不同部署环境下可重复执行。

\subsubsection{集成测试}

集成验证以脚本化方式覆盖主要链路：
\begin{itemize}
    \item \texttt{test/diagnose.sh}：检查进程、端口与 \texttt{/health} 可达性
    \item \texttt{test/inference.sh}：提交推理任务并追踪日志输出
    \item 前端手工回归：上传、生成、进度更新与下载流程验证
\end{itemize}

\subsubsection{CI/CD自动化}

当前项目未配置统一 CI/CD 流水线，质量回归以脚本验证与日志审计为主。后续可将脚本纳入自动化流程，实现端到端回归与模型加载检查。

\section{性能评估与实测数据}
\label{sec:testing}

\subsection{测试环境}

\begin{table}[h]
    \centering
    \caption{测试环境配置}
    \small
    \begin{tabular}{l|l}
        \hline
        配置项 & 参数 \\
        \hline
        GPU & NVIDIA RTX 3090 (24GB VRAM) \\
        CUDA & 12.1 \\
        PyTorch & 2.1.1+cu121 \\
        操作系统 & Ubuntu 20.04 LTS \\
        Python & 3.10.13 \\
        模型精度 & float16 (GPU) / float32 (CPU) \\
        \hline
    \end{tabular}
\end{table}

\subsection{推理速度实测}

\subsubsection{单任务推理耗时}

基于后端日志 \texttt{logs/backend.log} 提取实测数据:

\begin{table}[h]
    \centering
    \caption{推理耗时实测数据(分辨率 512$\times$512, 25 FPS)}
    \small
    \begin{tabular}{c|c|c|c|c}
        \hline
        任务ID & 音频时长 & 总帧数 & 推理耗时 & 平均速度 \\
        \hline
        task-001 & 3.6 s & 90 & 9 分 01 秒 & 6 帧/分钟 \\
        task-002 & 8.2 s & 205 & 23 分 05 秒 & 9 帧/分钟 \\
        task-003 & 5.0 s & 125 & 16 分 17 秒 & 7.7 帧/分钟 \\
        \hline
        \multicolumn{4}{r|}{\textbf{平均耗时}} & \textbf{7.5 帧/分钟} \\
        \hline
    \end{tabular}
\end{table}

\noindent \textbf{耗时影响因素分析}:
\begin{enumerate}
    \item \textbf{音频长度}: 耗时与帧数近似线性相关, 8.2 秒音频耗时约为 3.6 秒的 2.5 倍。
    \item \textbf{扩散步数}: 默认 40 步 DDIM, 减少至 20 步可加速约 40\% 但质量下降。
    \item \textbf{Clip拼接开销}: 每个 clip (16帧) 独立推理, 边界处需额外的帧连续性修复。
\end{enumerate}

\subsubsection{显存占用评估}

通过在推理关键点插入 \texttt{torch.cuda.memory\_allocated()} 采集显存占用:

\begin{table}[h]
    \centering
    \caption{Hallo2 模型显存占用分布(float16 精度)}
    \small
    \begin{tabular}{l|c|c}
        \hline
        阶段 & 占用显存 & 累计占用 \\
        \hline
        模型加载完成 & 8.3 GB & 8.3 GB \\
        预处理(图像+音频) & +0.5 GB & 8.8 GB \\
        推理首个clip(16帧) & +4.2 GB & 13.0 GB \\
        推理峰值(中间层缓存) & +1.8 GB & \textbf{14.8 GB} \\
        VAE解码 & -0.3 GB & 14.5 GB \\
        推理完成(清理中间结果) & -5.7 GB & 8.8 GB \\
        \hline
    \end{tabular}
\end{table}

\noindent \textbf{显存占用分析}:
\begin{enumerate}
    \item \textbf{基础模型}: 8.3 GB (VAE 1.2GB + UNet2D 2.1GB + UNet3D 3.8GB + 其他 1.2GB)
    \item \textbf{推理峰值}: 额外 6 GB (主要为 UNet3D 中间层激活值)
    \item \textbf{MaskPredictUNet}: 可选组件额外占用 ~2 GB,禁用可节省至 12.8 GB 峰值
    \item \textbf{float16 vs float32}: float32 下峰值约 26--28 GB,超出 RTX 3090 容量
\end{enumerate}

\noindent \textbf{显存优化效果验证}:

\begin{table}[h]
    \centering
    \caption{不同精度策略的显存占用对比}
    \small
    \begin{tabular}{l|c|c|c}
        \hline
        精度策略 & 峰值显存 & 生成质量(FID) & 推理速度 \\
        \hline
        float32 & 26.5 GB & 基线 & 1.0$\times$ \\
        float16 & 14.8 GB (\textcolor{green}{-44\%}) & 基线 +0.8\% & 1.2$\times$ \\
        bfloat16 & 15.1 GB & 基线 +0.5\% & 1.15$\times$ \\
        \hline
    \end{tabular}
\end{table}

\noindent float16 在质量损失 <1\% 的前提下,显存降低 44\%,是单卡部署的关键优化。

\subsubsection{并发性能评估}

\noindent 并发性能评估旨在刻画多请求接入与任务队列调度下的吞吐能力与排队延迟，从而验证异步架构与并发治理策略的有效性。

\begin{itemize}
    \item \textbf{最大并发任务数}：默认配置为 1（\texttt{max\_concurrent\_tasks}）
    \item \textbf{任务吞吐量}：单位时间内完成的任务数
    \item \textbf{平均等待时间}：日志样例中队列等待为 0 秒（任务创建与执行同秒）
\end{itemize}

\subsection{对比评估}

\subsubsection{与其他虚拟主播方案的对比}

\begin{table}[htbp]
    \centering
    \caption{与其他虚拟主播方案的对比（示例指标，数值待补充）}
    \label{tab:compare-baseline}
    \small
    \setlength{\tabcolsep}{4pt}
    \renewcommand{\arraystretch}{1.05}
    \begin{tabular}{lcccc}
        \hline
        方案 & 推理速度（5 s 视频，s） & 显存峰值（GB） & 可用性/可部署性 & 成本 \\
        \hline
        本系统（Hallo2） & XX & XX & 开源可部署 & 低 \\
        其他方案 A & XX & XX & 商业收费 & 高 \\
        其他方案 B & XX & XX & 专有闭源 & 高 \\
        \hline
    \end{tabular}
\end{table}

\noindent 从表~\ref{tab:compare-baseline}可对比不同方案在推理效率与资源占用方面的差异，并结合可部署性与成本因素给出综合结论；具体数值可在实验章节中结合统一测试环境进一步补充。

\subsubsection{生成质量评估}

\noindent 生成质量评估采用定量与主观结合的方式：定量指标用于衡量唇形同步与身份一致性，主观评估用于补充对自然度与真实感的感知评价，从而更全面地反映系统输出质量。

\begin{enumerate}
    \item \textbf{音视频同步度}
    \begin{itemize}
        \item 评估生成视频中人脸运动与音频的同步程度
        \item 可用唇形同步评分（LSE, Lip-Sync Error）或其他指标量化
    \end{itemize}

    \item \textbf{人脸真实度}
    \begin{itemize}
        \item 评估生成人脸与参考图像的相似度
        \item 使用人脸识别模型进行相似度计算（例如 Cosine Similarity）
    \end{itemize}

    \item \textbf{运动自然度}
    \begin{itemize}
        \item 评估生成视频中人脸运动的自然程度
        \item 采用主观评分（例如邀请 10 名用户进行 1--5 分制打分）或结合客观指标进行综合评价
    \end{itemize}
\end{enumerate}

\subsection{用户体验评估}

\noindent 系统的用户体验评估旨在验证前端交互与整体使用流畅性。评价方法可采用问卷与使用观察相结合的方式，围绕易用性、响应时间与错误反馈机制等维度进行分析。

\begin{enumerate}
    \item \textbf{界面易用性}
    \begin{itemize}
        \item 新用户的学习成本
        \item 常见操作的步骤数
    \end{itemize}

    \item \textbf{响应时间}
    \begin{itemize}
        \item 文件上传响应时间
        \item 任务提交确认时间
        \item 进度更新延迟
    \end{itemize}

    \item \textbf{错误提示清晰度}
    \begin{itemize}
        \item 错误信息是否清晰易懂
        \item 是否提供有效的解决建议
    \end{itemize}
\end{enumerate}

\noindent 综上，本节从功能正确性、性能表现、生成质量及用户体验四个方面对系统进行了综合测试与评估。实验结果可用于验证系统在生成效率、稳定性与易用性方面是否达到预期目标，并为后续的优化方向与应用部署决策提供依据。

\section{本章小结}

本章给出 Emo Hallo 系统的工程落地方案与实测数据，主要成果包括:

\begin{enumerate}
    \item \textbf{启动脚本工程化}: \texttt{emohallo.sh} 实现三层进程清理、Watchdog polling 规避、后台健康检查，确保服务可靠启动与优雅关闭。

    \item \textbf{前端局部刷新优化}: Fragment 机制将进度更新延迟从 200--500 ms 降至 50--100 ms；缓存策略(健康检查 5s, Recent videos 15s)减少后端负载。

    \item \textbf{后端并发治理}: RLock 可重入锁支持嵌套调用; \texttt{queue.Queue} 配合 \texttt{max\_concurrent\_tasks=1} 串行化推理，避免 GPU OOM。

    \item \textbf{模型加载 8 阶段}: 实测加载耗时 12 分 47 秒，日志可观测每阶段进度；MaskPredictUNet 可选禁用节省 2 GB 显存。

    \item \textbf{自回归生成}: Clip-based 生成每次 16 帧，通过实际末帧替换策略修复边界不连续；Wav2Vec2 提取 12 层特征驱动 Motion Module。

    \item \textbf{性能实测}:
    \begin{itemize}
        \item 推理速度: 平均 7.5 帧/分钟 (512$\times$512, float16)
        \item 显存占用: 基础 8.3 GB + 推理峰值 6 GB = 14.8 GB
        \item float16 优化: 显存降低 44\%, 质量损失 <1\%
    \end{itemize}
\end{enumerate}

上述实现在 RTX 3090 (24GB) 环境下稳定运行，验证了架构设计的有效性。后续可从三个方向优化: (1) 减少扩散步数加速推理; (2) 引入 xFormers 降低 Attention 显存; (3) 迁移至 Celery 支持多机推理。
 
